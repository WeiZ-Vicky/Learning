{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d84101",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<h1>The Traveling Salesman Problem</h1>\n",
    "<br><br>\n",
    "<li>Given a graph, find the shortest circuit that goes through all the vertices exactly once</li>\n",
    "<li>The TSP is an NP complete problem and typically needs to be solved using a heuristic algorithm</li>\n",
    "<li>We'll solve the problem using <span style=\"color:blue\">genetic algorithms</span> and graphx's <span style=\"color:blue\">pregel</span> algorithm</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f8c5c",
   "metadata": {},
   "source": [
    "<h1>Digression: Serialization</h1>\n",
    "<li>Serialization is the process of converting an object into a <b>byte stream</b> so that it can be sent from one machine to another</li>\n",
    "<li>Since Spark works in a cluster format, with a master and workers, objects are constantly moving between different nodes</li>\n",
    "<li>If an object cannot be serialized, and a communication is attempted, a nonserializable exception is thrown</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228d39f",
   "metadata": {},
   "source": [
    "<li>The following example can be serialized</li>\n",
    "<li>the function - myFunc - has all the data it needs to execute</li>\n",
    "<li>and only myFunc needs to be serialized</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7ffb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://dyn-209-2-224-122.dyn.columbia.edu:4043\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1668009642139)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "rdd: org.apache.spark.rdd.RDD[Double] = ParallelCollectionRDD[0] at parallelize at <console>:24\n",
       "defined object Test\n",
       "res0: Array[Double] = Array(2.0, 4.0, 6.0, 8.0, 10.0)\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = sc.parallelize(Array(1.0,2.0,3.0,4.0,5.0))\n",
    "object Test {\n",
    "    def myFunc = rdd.map(_ * 2)\n",
    "}\n",
    "Test.myFunc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff2447",
   "metadata": {},
   "source": [
    "<li>Instead of multiplying by 2, we want to multiply by a variable</li>\n",
    "<li>We get a \"task not serializable\" error</li>\n",
    "<li>this is because myFunc needs access to multiplier and can't be serialized</li>\n",
    "<li>the entire Test would need to be serialized but it isn't serializable automatically</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367bec98",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": " Task not serializable",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Task not serializable",
      "  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:444)",
      "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:416)",
      "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:163)",
      "  at org.apache.spark.SparkContext.clean(SparkContext.scala:2491)",
      "  at org.apache.spark.rdd.RDD.$anonfun$map$1(RDD.scala:414)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)",
      "  at org.apache.spark.rdd.RDD.map(RDD.scala:413)",
      "  at Test$.myFunc(<console>:29)",
      "  ... 38 elided",
      "Caused by: java.io.NotSerializableException: Test$",
      "Serialization stack:",
      "\t- object not serializable (class: Test$, value: Test$@197a7125)",
      "\t- element of array (index: 0)",
      "\t- array (class [Ljava.lang.Object;, size 1)",
      "\t- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;)",
      "\t- object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class Test$, functionalInterfaceMethod=scala/runtime/java8/JFunction1$mcDD$sp.apply$mcDD$sp:(D)D, implementation=invokeStatic Test$.$anonfun$myFunc$1:(LTest$;D)D, instantiatedMethodType=(D)D, numCaptured=1])",
      "\t- writeReplace data (class: java.lang.invoke.SerializedLambda)",
      "\t- object (class Test$$$Lambda$2947/0x000000080109f040, Test$$$Lambda$2947/0x000000080109f040@7e760265)",
      "  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)",
      "  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:49)",
      "  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)",
      "  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:441)",
      "  ... 47 more",
      ""
     ]
    }
   ],
   "source": [
    "val rdd = sc.parallelize(Array(1.0,2.0,3.0,4.0,5.0))\n",
    "object Test {\n",
    "    val multiplier = 2\n",
    "    def myFunc = rdd.map(_ * multiplier)//worker does not know what is multiplier\n",
    "}//object->only one instance of class\n",
    "Test.myFunc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f06901a",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": " Task not serializable",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Task not serializable",
      "  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:444)",
      "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:416)",
      "  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:163)",
      "  at org.apache.spark.SparkContext.clean(SparkContext.scala:2491)",
      "  at org.apache.spark.rdd.RDD.$anonfun$map$1(RDD.scala:414)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:406)",
      "  at org.apache.spark.rdd.RDD.map(RDD.scala:413)",
      "  at Test$.myFunc(<console>:30)",
      "  ... 38 elided",
      "Caused by: java.io.NotSerializableException: Test$",
      "Serialization stack:",
      "\t- object not serializable (class: Test$, value: Test$@13fab152)",
      "\t- element of array (index: 0)",
      "\t- array (class [Ljava.lang.Object;, size 1)",
      "\t- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;)",
      "\t- object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class Test$, functionalInterfaceMethod=scala/runtime/java8/JFunction1$mcDD$sp.apply$mcDD$sp:(D)D, implementation=invokeStatic Test$.$anonfun$myFunc$1:(LTest$;D)D, instantiatedMethodType=(D)D, numCaptured=1])",
      "\t- writeReplace data (class: java.lang.invoke.SerializedLambda)",
      "\t- object (class Test$$$Lambda$3011/0x00000008010d1040, Test$$$Lambda$3011/0x00000008010d1040@5a97711f)",
      "  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)",
      "  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:49)",
      "  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)",
      "  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:441)",
      "  ... 47 more",
      ""
     ]
    }
   ],
   "source": [
    "val rdd = sc.parallelize(Array(1.0,2.0,3.0,4.0,5.0))\n",
    "val multiplier = 2\n",
    "object Test {\n",
    "    def myFunc = rdd.map(_ * multiplier)//worker does not know what is multiplier\n",
    "}//object->only one instance of class\n",
    "Test.myFunc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca63110",
   "metadata": {},
   "source": [
    "<li>We need to make it serializable</li>\n",
    "<li>Add the trait (flavor) <b>Serializable</b> to the class definition</li>\n",
    "<li>This has the downside that we might be tempted to serialize everything, which adds a lot of overhead to the application</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11634b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd: org.apache.spark.rdd.RDD[Double] = ParallelCollectionRDD[4] at parallelize at <console>:26\n",
       "defined object Test\n",
       "res3: Array[Double] = Array(2.0, 4.0, 6.0, 8.0, 10.0)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = sc.parallelize(Array(1.0,2.0,3.0,4.0,5.0))\n",
    "object Test extends Serializable {\n",
    "    val multiplier = 2\n",
    "    def myFunc = rdd.map(_ * multiplier)\n",
    "}//packaged\n",
    "Test.myFunc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41573cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd: org.apache.spark.rdd.RDD[Double] = ParallelCollectionRDD[6] at parallelize at <console>:26\n",
       "multiplier: Int = 2\n",
       "defined object Test\n",
       "res4: Array[Double] = Array(2.0, 4.0, 6.0, 8.0, 10.0)\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = sc.parallelize(Array(1.0,2.0,3.0,4.0,5.0))\n",
    "val multiplier = 2\n",
    "object Test extends Serializable {\n",
    "//     val multiplier = 2\n",
    "    def myFunc = rdd.map(_ * multiplier)\n",
    "}//packaged\n",
    "Test.myFunc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20b454",
   "metadata": {},
   "source": [
    "<li>Instead: Make sure that every variable in the map is instantiated inside myFunc</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b75c410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd: org.apache.spark.rdd.RDD[Double] = ParallelCollectionRDD[8] at parallelize at <console>:27\n",
       "defined object Test\n",
       "res5: Array[Double] = Array(2.0, 4.0, 6.0, 8.0, 10.0)\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = sc.parallelize(Array(1.0,2.0,3.0,4.0,5.0))\n",
    "object Test {\n",
    "    val multiplier = 2\n",
    "    def myFunc = {\n",
    "        val multi = multiplier\n",
    "        rdd.map(_ * multi)\n",
    "    }\n",
    "}\n",
    "Test.myFunc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb54d0c",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">The TSP dataset</span>\n",
    "<br><br>\n",
    "<li>Each \"city\" is a point (x,y) on a grid</li>\n",
    "<li>distances between cities are the euclidean distance</li>\n",
    "<li>each city is connected to every other city</li>\n",
    "<li>each city has a unique id</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f78dce",
   "metadata": {},
   "source": [
    "<li>Each city is a point on the grid represented by a <b>Point</b> object</li>\n",
    "<li>And we have an array containing all the cities</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b6722",
   "metadata": {},
   "source": [
    "<li>Generate random (x,y) coordinates for each city</li>\n",
    "<li>And give each city a unique id (0 to 20)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551cde4",
   "metadata": {},
   "source": [
    "<h4>The cost matrix</h4>\n",
    "<li>We're using the euclidean distance</li>\n",
    "<li>So, the distance from city at $(x_1,y_1)$ to city at $(x_2,y_2)$ is:</li>\n",
    "$ \\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Graph imports\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.graphx._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d82553",
   "metadata": {},
   "outputs": [],
   "source": [
    "val number_of_cities = 20\n",
    "val grid_size = 500 //500x500 2-d space. A Point will be (x,y) on this grid\n",
    "val max_generations = 20\n",
    "//Create a Point case class\n",
    "\n",
    "//We'll make Point serializable because it will move between nodes multiple times\n",
    "case class Point(var x: Int = 0, var y: Int = 0) extends Serializable\n",
    "\n",
    "//val number_of_cities:Int = 20;\n",
    "\n",
    "//Create an array of cities\n",
    "val cities = new Array[Point](number_of_cities)\n",
    "\n",
    "//And an array of ids for each city\n",
    "val v_ids = new Array[Long](number_of_cities)\n",
    "//val grid_size=500\n",
    "\n",
    "//Randomly assign cities to points on the grid\n",
    "val r = scala.util.Random\n",
    "for (i <- 0 to number_of_cities-1){\n",
    "    cities(i) = new Point(r.nextInt(grid_size)+10,r.nextInt(grid_size)+10)\n",
    "    v_ids(i) = i.toLong;\n",
    "    \n",
    "}\n",
    "\n",
    "//val citiesRDD = v_ids.zip(cities)\n",
    "val costmatrix = Array.ofDim[Double](number_of_cities,number_of_cities);\n",
    "//compute an euclidean distance matrix: sqrt((x2-x1)^2+(y2-y1)^2)\n",
    "for (i <-0 to number_of_cities-1) {\n",
    "    for (j <-0 to number_of_cities-1) {  \n",
    "        val deltax = cities(i).x-cities(j).x;\n",
    "        val deltay = cities(i).y-cities(j).y;\n",
    "        costmatrix(i)(j) =  math.sqrt(deltax*deltax+deltay*deltay).round;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b81395",
   "metadata": {},
   "source": [
    " <br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Genetic Algorithms</span>\n",
    "<br><br>\n",
    "<li>mimics natural selection to arrive at a solution</li>\n",
    "<ul>\n",
    "    <li>problem is encoded in the form of a chromosome</li>\n",
    "    <li>a population of chromosomes is generated</li>\n",
    "    <li>a metric for \"goodness\" of the population is defined</li>\n",
    "    <li>an evolutionary process moves the population in the direction of \"better\" solutions</li>\n",
    "</ul>\n",
    "<li>often used for optimization or search</li>\n",
    "<li>uses heuristics (we cannot prove that the solution is optimal)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7518566",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">natural selection</span>\n",
    "<li>Chromosomes from two parents are combined and a child chromosome is generated</li>\n",
    "<li>The combination process uses two heuristics</li>\n",
    "<ul>\n",
    "    <li><span style=\"color:blue\">crossover</span>: if a chromosome contains n genes, then the first m genes from parent 1 and the m+1 to n genes from parent 2 are combined into the new chromosome. The crossover process must ensure that the <b>resulting chromosome defines a consistent solution</b></li>\n",
    "    <li><span style=\"color:blue\">mutation</span>: some genes are arbitrarily changed when the offspring chromosome is created. Mutation rates are typically very low. The mutation process must ensure that the <b>resulting chromosome defines a consistent solution</b></li>\n",
    "</ul>\n",
    "<li><span style=\"color:blue\">population</span>: A collection of individuals at a point in time</li>\n",
    "<li>In natural selection, the environment decides which individuals are best able to survive in it and, over time, the chromosomes of the species evolves. As the environment changes, so do the characteristics of the species</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd9e51",
   "metadata": {},
   "source": [
    "<img src=\"crossover.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef25429",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Rough methodology</span>\n",
    "<br><br>\n",
    "<li>create a representation for the chromosome of an individual. This is problem specific but, usually, a chromosome is a candidate solution</li>\n",
    "<li>for example, in linear regression, a chromosome may be the co-efficients of the regression equation. Each beta is synonymous with a gene</li>\n",
    "<li>decide on a metric for evaluating the \"fitness\" of an individual</li>\n",
    "<li>for example, in linear regression, fitness may the the root mean square error of actual and predicted values using the co-efficients in the chromosome</li>\n",
    "<li>define crossover and mutation methods</li>\n",
    "<ul>\n",
    "    <li>in regression, crossover could involve combining co-efficients from chromosome 1 with co-efficients from chromosome 2</li>\n",
    "    <li>in regression, mutation could involve tweaking a co-efficient in the offspring randomly (within preset parameters)\n",
    "    <li>more generally, as we'll see with the TSP, crossover and mutation may be more complicated because the resulting chromosome may need to satisfy certain constraints to be valid</li>\n",
    "    </ul>\n",
    "    <p>\n",
    "    <b>Evolution</b>\n",
    "    <li>create a population of individuals to form generation 0</li>\n",
    "    <li>create a new generation using crossover and mutation to create new chromosomes</li>\n",
    "    <li>the algorithm gives an edge to \"fitter\" chromosomes when selecting parents for crossover</li>\n",
    "    <li>repeat for n-generations and, hopefully, the best chromosomes in later generations will be \"fitter\" than the best chromosomes in early generations</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20623e76",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Genetic Algorithms and the TSP</span>\n",
    "<br><br>\n",
    "<span style=\"color:blue;font-size:large\">Chromosomes</span>\n",
    "<br>\n",
    "<li><span style=\"color:red\">Solution structure</span>: A candidate solution to the traveling salesman problem is a circuit that goes through every node exactly once</li>\n",
    "<li>If there are 5 vertices (1,2,3,4,5), then (4,2,1,3,5); (2,4,1,3,5); (5,2,3,1,4), etc. are candidate solutions</li>\n",
    "<li>Therefore, a <span style=\"color:red\">chromosome</span> is represented as a n-gene array, where n is the number of cities</li>\n",
    "<li>A <b>consistent</b> solution is one in which no city is repeated</li>\n",
    "<li>The <b>cost</b> associated with a solution is the sum of distances between adjacent cities in the circuit. For example, if a solution is (3,2,1,4,5), then the cost associated with the solution is:\n",
    "    $ c_{3,2} + c_{2,1} + c_{1,4} + c_{4,5} + c_{5,3}$ where $c_{i,j}$ is the distance between city i and city j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798ad64",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\"> Crossover</span>\n",
    "<br><br>\n",
    "<li>Crossovers are a little complicated</li>\n",
    "<li>Example: c1 = (1,3,2,7,5,6,4); c2 = (4,2,3,1,6,7,5)</li>\n",
    "<li>ordinary crossover would take the first 3 elements of c1 and the last 4 elements of c2 and combine them</li>\n",
    "<li>but this gives us (1,3,2,1,6,7,5) which is not a valid solution (since 1 is repeated)</li>\n",
    "<li>We need to crossover the two chromosomes while preserving the rules of a circuit</li>\n",
    "<li>A method known as PMX Special (Partially Mapped Crossover special) attempts to pass on circuit knowledge to the child while also keeping to the circuit rules</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d94225",
   "metadata": {},
   "source": [
    "<img src=\"crossover1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c41be5",
   "metadata": {},
   "source": [
    "<img src=\"crossover2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38cd2df",
   "metadata": {},
   "source": [
    "<img src=\"crossover3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2bfc25",
   "metadata": {},
   "source": [
    "<img src=\"crossover4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b308eff1",
   "metadata": {},
   "source": [
    "<img src=\"crossover5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46162612",
   "metadata": {},
   "source": [
    "<img src=\"crossover6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85aebc2",
   "metadata": {},
   "source": [
    "<img src=\"crossover7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c40b895",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Mutation</span>\n",
    "<br><br>\n",
    "<li>Mutation also presents a problem, we can't just change a gene because that would mess with the circuit</li>\n",
    "<li>Instead, we'll mutate a chromosome by exchanging genes in the chromosome</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5606ca",
   "metadata": {},
   "source": [
    "<img src=\"mutation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4332b57",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Reproduction and evolutionary functions</span>\n",
    "<br><br>\n",
    "<li><span style=\"color:blue\">create_offspring</span> creates a child from two parents using crossover and mutation</li>\n",
    "<li><span style=\"color:blue\">compute_fitness_of_chromosome</span> returns a (chromosome,fitness) tuple for a given chromosome</li>\n",
    "<li>Note that both these functions will be unique to the problem being solved because they depend on the structure of the chromosome</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e430c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "//create_offspring takes two chromosomes (Arrays of Int) as argument\n",
    "//and returns a new chromosome (Array of Int)\n",
    "def create_offspring(parent1:Array[Int],parent2:Array[Int]):Array[Int] = {\n",
    "    val numGenes = parent1.length\n",
    "    //Initialize a random number generator\n",
    "    val r = scala.util.Random\n",
    "\n",
    "    //Create copies of the parents\n",
    "    //clone creates a deep copy, not just a new pointer to the array\n",
    "    val parent1_c = parent1.clone();\n",
    "    val parent2_c = parent2.clone();\n",
    "    \n",
    "    //Create an empty offspring\n",
    "    val offspring = new Array[Int](parent1_c.length);\n",
    "    \n",
    "    //Randomly choose a crossover point\n",
    "    val crossoverpoint = r.nextInt(parent1_c.length-2);\n",
    "    \n",
    "    //PMX special CrossOver Method\n",
    "    for (x <-0 to crossoverpoint){\n",
    "      val gen = parent2_c(x);\n",
    "      offspring(x) = gen \n",
    "      for (y <- (x+1) to parent1_c.length-1) {      \n",
    "         if (parent1_c(y) == gen) { \n",
    "             parent1_c(y) = parent1_c(x) \n",
    "           }\n",
    "      }\n",
    "    }\n",
    "    //copy remaining genes from parent 1 to offspring\n",
    "    for (y <- crossoverpoint+1 to parent1_c.length-1)\n",
    "        offspring(y) = parent1_c(y);\n",
    "\n",
    "    //mutation: swap with a .03 probability\n",
    "    if (r.nextInt(100) < 3) { \n",
    "        val m1 = r.nextInt(numGenes)\n",
    "        val m2 = r.nextInt(numGenes)\n",
    "        val gen1 = offspring(m1)\n",
    "        val gen2 = offspring(m2)\n",
    "        offspring(m1) = gen2\n",
    "        offspring(m2) = gen1\n",
    "        //println(m1,m2,gen1,gen2)\n",
    "    }\n",
    "\n",
    "    return offspring\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "val c1 = Array(0,1,3,2,4,7,6,5)\n",
    "val c2 = Array(3,7,1,5,0,4,6,2)\n",
    "create_offspring(c1,c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a11439",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">fitness</span>\n",
    "<br><br>\n",
    "<li>given the circuit, the fitness is the travel distance of the circuit</li>\n",
    "<li>add up the distances and then add the distance from the last city to the first city</li>\n",
    "<li>We'll store the chromosome and its cost as a paired tuple</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness_of_chromosome(distanceMatrix: Array[Array[Double]], chromosome :Array[Int]) = {\n",
    "    var cost = 0.0;\n",
    "    val numGenes = chromosome.length\n",
    "    for (j <-0 to numGenes-2) { \n",
    "        cost += distanceMatrix(chromosome(j))(chromosome(j+1))\n",
    "    }\n",
    "    cost += distanceMatrix(chromosome(numGenes-1))(chromosome(0))\n",
    "    (chromosome,cost)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9068dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val ch = Array(0, 1, 3, 2, 4, 7, 6, 5)\n",
    "compute_fitness_of_chromosome(costmatrix,ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bc900",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Populations</span>\n",
    "<br><br>\n",
    "<li>A population is a collection of chromosomes</li>\n",
    "<li>We'll define a population as an array of (chromosome,fitness) pairs</li>\n",
    "<li>A population will have the following data associated with it:</li>\n",
    "<ol>\n",
    "    <li><span style=\"color:blue\">cost matrix</span>: Though this is constant, we need to store this with each population to ensure serializability</li>\n",
    "    <li><span style=\"color:blue\">chromosomes</span>: The collection of individuals in the population</li>\n",
    "    <li><span style=\"color:blue\">generation</span>: As the population evolves, the individuals change. Each generation has its own population and we need to include a generation identifier with a population</li>\n",
    "    <li><span style=\"color:blue\">fittest individuals</span>: the chromosomes that have the best fitness. Useful because the most fit chromosomes will correspond to the best solution at each generation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ace17",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class PopulationData (val CostMatrix: Array[Array[Double]], \n",
    "                           val GeneSequences: Array[(Array[Int],Double)], \n",
    "                           var GenerationNumber:Int,\n",
    "                           var best_sequences:List[(Int,Array[Int],Int,Double)]) \n",
    "                            extends Serializable \n",
    "val r = scala.util.Random\n",
    "\n",
    "val GeneSequences: Array[(Array[Int],Double)] = Array.ofDim[(Array[Int],Double)](5000);\n",
    "val GenSequencesFilled = GeneSequences.map(x=> {(scala.util.Random.shuffle((0 to number_of_cities-1)).toArray,0.0)})\n",
    "\n",
    "val best_sequences = List[(Int,Array[Int],Int,Double)]()\n",
    "val PopData = new PopulationData(costmatrix,GenSequencesFilled,0,best_sequences);  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737cb488",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Evolution using Pregel</span>\n",
    "<br><br>\n",
    "<li>Our evolutionary strategy is as follows:</li>\n",
    "<li>create 8 (or any n) populations</li>\n",
    "<li>each population is a vertex on a graph</li>\n",
    "<li>some vertices are connected to others (but the graph is fully connected)</li>\n",
    "<li>in each pregel superstep\n",
    "    <ul>\n",
    "        <li>send Msg: sends a subset of chromosomes (solutions) containing the fittest solutions along with the best chromosome history</li>\n",
    "        <li>merge Msg: picks the best chromosome (from the arriving messages) and its history as the best chromosome</li>\n",
    "        <li>vertex program: creates a new population through crossover and mutation from the arriving message</li>\n",
    "    </ul>\n",
    "<li>After n generations (n supersteps), the evolution halts and we'll search the best chromosomes in each of the 8 populations to find the best solution</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ab992",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">The Graph</span>\n",
    "<br><br>\n",
    "<li>The code below constructs a fully connected graph</li>\n",
    "<li>approximately, the first half vertices are connected, in both directions, with the second half vertices</li>\n",
    "<li>and I arbitrarily connect the first two and the last two vertices in both directions</li>\n",
    "<li>Note: the code won't work with an odd number of communities!</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9affc5bf",
   "metadata": {},
   "source": [
    "<img src=\"pregel graph.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaaf523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.graphx._\n",
    "\n",
    "val number_of_communities = 8\n",
    "val vertexArray = new Array[(Long,PopulationData)](number_of_communities)\n",
    "for (i <- 0 to number_of_communities-1)\n",
    "    vertexArray(i) = ((i+1).toLong,PopData)\n",
    "val vertexRDD = sc.makeRDD(vertexArray)\n",
    "\n",
    "\n",
    "val number_of_edges = vertexArray.length/2 * (vertexArray.length - vertexArray.length/2) *2 + 4\n",
    "var index = 0\n",
    "val edgeArray = new Array[Edge[Boolean]](number_of_edges)\n",
    "for (i <- 0 to vertexArray.length/2-1)\n",
    "    for (j <- vertexArray.length/2 to vertexArray.length-1) {\n",
    "        edgeArray(index) = Edge(i+1.toLong,j+1.toLong,true)\n",
    "        edgeArray(index+1) = Edge(j+1.toLong,i+1.toLong,true)\n",
    "        index=index+2\n",
    "    }\n",
    "edgeArray(index) = Edge(1L,2L,true)\n",
    "edgeArray(index+1) = Edge(2L,1L,true)\n",
    "edgeArray(index+2) = Edge(vertexArray.length.toLong,vertexArray.length-1.toLong,true)\n",
    "edgeArray(index+3) = Edge(vertexArray.length-1.toLong,vertexArray.length.toLong,true)\n",
    "val edgeRDD = sc.makeRDD(edgeArray)  \n",
    "\n",
    "val myGraph = Graph(vertexRDD, edgeRDD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af8a7a",
   "metadata": {},
   "source": [
    "<img src=\"sendMsg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendMsg(et: EdgeTriplet[PopulationData, Boolean]): Iterator[(VertexId, PopulationData)] = {\n",
    "    val selection = et.srcAttr.GeneSequences.sortBy(x => x._2).take(1000)\n",
    "\n",
    "    val fittestsequence = et.srcAttr.GeneSequences.sortBy(x => x._2).take(1)\n",
    "    val fittestsequencehistory = (et.srcAttr.GenerationNumber+1,fittestsequence(0)._1,et.srcId.toInt,fittestsequence(0)._2) :: et.srcAttr.best_sequences\n",
    "    val evodat = new PopulationData(et.srcAttr.CostMatrix,selection,et.srcAttr.GenerationNumber+1,fittestsequencehistory)\n",
    "    Iterator((et.dstId,evodat)) \n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e863068",
   "metadata": {},
   "source": [
    "<img src=\"mergeMsg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeMsg(msg1: PopulationData, msg2: PopulationData): PopulationData = {\n",
    "    //println(msg1.GenerationNumber,msg2.GenerationNumber,msg1.GeneSequences.length,msg1.best_sequences.length)\n",
    "\n",
    "    val x = if (msg1.best_sequences(0)._4 < msg2.best_sequences(0)._4) msg1.best_sequences else msg2.best_sequences\n",
    "    val allparents = msg1.GeneSequences.union(msg2.GeneSequences)\n",
    "    val ParentPopulation = new PopulationData(msg1.CostMatrix,allparents,msg1.GenerationNumber,x)\n",
    "    ParentPopulation\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f4e7a",
   "metadata": {},
   "source": [
    "<img src=\"vertexProgram.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vProg(v: VertexId, attr:  PopulationData, msg: PopulationData): PopulationData = { \n",
    "      //println(msg.GenerationNumber,v,msg.GeneSequences.length,msg.best_sequences.length)\n",
    "\n",
    "    val r = scala.util.Random\n",
    "    val newPopulation = Array.ofDim[(Array[Int],Double)](5000)\n",
    "    for (i <-0 to 4999) \n",
    "    {\n",
    "       //get random indexes\n",
    "       val i1 = r.nextInt(msg.GeneSequences.length-1)\n",
    "       val i2 = r.nextInt(msg.GeneSequences.length-1)\n",
    "       val i3 = r.nextInt(msg.GeneSequences.length-1)\n",
    "       val i4 = r.nextInt(msg.GeneSequences.length-1)\n",
    "       val f1 = msg.GeneSequences(i1)._2\n",
    "       val f2 = msg.GeneSequences(i2)._2\n",
    "       val f3 = msg.GeneSequences(i3)._2\n",
    "       val f4 = msg.GeneSequences(i4)._2              \n",
    "       val p1 = if (f1 < f2) msg.GeneSequences(i1) else msg.GeneSequences(i2)\n",
    "       val p2 = if (f3 < f4) msg.GeneSequences(i3) else msg.GeneSequences(i4)\n",
    "\n",
    "       val child = create_offspring(p1._1,p2._1)\n",
    "       newPopulation(i) = (child,0)\n",
    "\n",
    "    }    \n",
    "    val sequence_with_fitness = newPopulation.map(y => {compute_fitness_of_chromosome(msg.CostMatrix,y._1)})\n",
    "    println(\"vertex: \",v,\" generation: \",attr.GenerationNumber,\" msg gen: \",msg.GenerationNumber)\n",
    "\n",
    "    val evodat = new PopulationData(attr.CostMatrix,sequence_with_fitness,msg.GenerationNumber,msg.best_sequences)\n",
    "    evodat;\n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba95e4",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Running pregel</span>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45914d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "java.time.LocalDateTime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val max_generations = 20\n",
    "val starttime = java.time.LocalDateTime.now;\n",
    "val t0 = System.nanoTime()\n",
    "//println(\"Evolution start: \" +   starttime); \n",
    "val resultgraph = myGraph.pregel(PopData, max_generations,EdgeDirection.Out)(vProg, sendMsg, mergeMsg)\n",
    "\n",
    "val t1 = System.nanoTime()\n",
    "//println(\"Elapsed time: \" + (t1 - t0) + \"ns\")\n",
    "val endtime = java.time.LocalDateTime.now;\n",
    "//println(\"Evolution ends at: \" +  endtime  + \" Duration in seconds: \" + (t1 - t0)*1.0/1000000000 ); \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea3048",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Results</span>\n",
    "<br><br>\n",
    "<li><span style=\"color:blue\">printBestResults</span> prints the best chromosome from each of the vertices</li>\n",
    "<li><span style=\"color:blue\">bestChromosomeHistory</span> prints the evolutionary history of a chromosome</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926056bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBestResults(g: Graph[PopulationData,Boolean]) = {\n",
    "    val v = g.vertices\n",
    "    val fittest_chromosome = v.map(t => t._2.best_sequences)\n",
    "        .map(s => s.sortBy(_._3)) //sort by fitness (lowest to highest)\n",
    "        .map(s => s(0))//get fittest\n",
    "        .collect\n",
    "        .foreach( t => {\n",
    "            print(\"Circuit: \" + t._2.mkString(\" \"))\n",
    "            print(\" found in generation: \" + t._1)\n",
    "            println(\" fitness: \" + t._4 )\n",
    "        })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35684a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "printBestResults(resultgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa59d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestChromosomeHistory(g: Graph[PopulationData,Boolean],vertex_id: Int) = {\n",
    "    val bests = resultgraph.vertices\n",
    "                    .filter(v=>v._1==1)\n",
    "                    .map(t=>t._2.best_sequences)\n",
    "                    .collect()(0)\n",
    "                     .foreach( t => {\n",
    "                                print(\"Circuit: \" + t._2.mkString(\" \"))\n",
    "                                print(\" found in generation: \" + t._1)\n",
    "                                println(\" fitness: \" + t._4 )\n",
    "                            })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestChromosomeHistory(resultgraph,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.awt.image.BufferedImage\n",
    "import java.awt.Font\n",
    "import java.awt.Color\n",
    "def path_to_image(vertices:Array[(Long,Point)], \n",
    "                  edges:Array[Edge[Int]],\n",
    "                  generation:Int, \n",
    "                  fitness:Double, \n",
    "                  pregelGraphVertexID:Int) = {\n",
    "    val img = new BufferedImage(550, 550, BufferedImage.TYPE_INT_RGB)\n",
    "    val g = img.createGraphics();\n",
    "    g.setColor(Color.WHITE)\n",
    "    g.fillRect(0, 0, 550, 550)\n",
    "    val myFont = new Font(\"Serif\", Font.BOLD, 14);  \n",
    "    g.setFont(myFont)\n",
    "    //g.setRenderingHint(java.awt.RenderingHints.KEY_ANTIALIASING, java.awt.RenderingHints.VALUE_ANTIALIAS_ON)\n",
    "    g.setColor(Color.BLACK)\n",
    "    g.drawString(\"Generation:\" + generation.toString() + \" Populations Vertex ID:\"+ pregelGraphVertexID +\" Fitness:\" + fitness.toString(), 0, 540)\n",
    "     \n",
    "    for (v <- vertices) \n",
    "        g.fillOval(v._2.x-5, v._2.y-5, 10, 10);\n",
    "    for (e <- edges)\n",
    "        g.drawLine(vertices(e.srcId.toInt)._2.x, \n",
    "                   vertices(e.srcId.toInt)._2.y, \n",
    "                   vertices(e.dstId.toInt)._2.x, \n",
    "                   vertices(e.dstId.toInt)._2.y) \n",
    "    img    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cad299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.ByteArrayOutputStream;\n",
    "import javax.imageio.ImageIO\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "\n",
    "def drawtrip(circuit: Array[Int], \n",
    "             cities: Array[(Long,Point)], \n",
    "             file:String,\n",
    "             generation:Int,\n",
    "             fitness:Double,\n",
    "             pregelGraphVertexId:Int) :Unit = {\n",
    "    val sequence = circuit.map(_.toLong);  //Convert int vertex ids to long  \n",
    "    //Construct edges that correspond to the circuit\n",
    "    val EdgeArray:Array[Edge[Int]] = new Array[Edge[Int]](number_of_cities);\n",
    "    val tspVertices = sc.makeRDD(cities); \n",
    "    for (i <-0 to sequence.length-2)\n",
    "        EdgeArray(i) = new Edge(sequence(i),sequence(i+1),1) //add an edge of 1 unit length\n",
    "    EdgeArray(number_of_cities-1) = new Edge(sequence(number_of_cities-1),sequence(0),1); //close the trip\n",
    "    //val tspEdges = sc.makeRDD(EdgeArray); /\n",
    "    val img = path_to_image(cities,EdgeArray,generation,fitness,pregelGraphVertexId)\n",
    "    \n",
    "    //ImageIO.write(img, \"jpg\", new File(file))\n",
    "     \n",
    "       \n",
    "    val baos = new ByteArrayOutputStream();\n",
    "    ImageIO.write(img, \"jpg\", baos);\n",
    "     \n",
    "       \n",
    "    val pa = \"results1/Generation_\"+generation+\"_Node_\"+pregelGraphVertexId+\".jpg\";\n",
    "    val fs = FileSystem.get(sc.hadoopConfiguration)\n",
    "    val out = fs.create(new Path(pa))\n",
    "    out.write(baos.toByteArray());\n",
    "    out.close();      \n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec0f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "val example_history = resultgraph.vertices\n",
    "                    .filter(v=>v._1==1)\n",
    "                    .map(t=>t._2.best_sequences)\n",
    "                    .collect()(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282805a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_history.foreach(z => {\n",
    "   println(\"Generation:\" + z._1 + \" Node:\" + z._3 + \" Sequence:\" + z._2.mkString(\"-\")+ \" Fitness:\" + z._4)\n",
    "  drawtrip(z._2,v_ids.zip(cities),\"Generation_\"+z._1+\"_Node_\"+z._3+\".jpg\",z._1,z._4,z._3);\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e327c3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
