{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:red;font-size:60px\">Collaborative filtering example</span>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In <span style=\"color:blue\">collaborative filtering</span>, an algorithm uses available choices made by a user, along with the set of choices made by a large set of other users, to make recommendations for the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Author recommendation system</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"people authors graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><span style=\"color:red\">Initial data</span>: Ratings given by readers to authors. Not every reader rates every author so this graph is likely to be <span style=\"color:red\">sparsely connected</span></li>\n",
    "<li>Vertices in this graph are either authors or readers and edges are \"author reader connections\". Edge attributes are the ratings (1 to 5) gvien to the author</li>\n",
    "<li>The objective of the <span style=\"color:red\">recommender system</span> is to predict the rating that a reader will give to an unrated (by them) author</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">SVD++ and collaborative filtering</span>\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Collaborative filtering starts with a sparse matrix with people on one axis and authors on the other axis (since most people will have read only a few of the many million authors, this matrix is sparse)</li>\n",
    "<li>The general idea is to start by assuming that the authors (or movies, books, brands of cereal, etc.) can be grouped into k classes that represent some latent attribute of the authors (genres, for example) and then decomposing the large sparse matrix into a n x k and k x m matrix (n=number of people, m = number of authors, k=number of latent attributes)</li>\n",
    "<li>SVD++ combines singular value decomposition with graph neighborhood models to compute factor weightings in the decomposed matrix</li> \n",
    "<li>If interested, see <a href=\"https://people.engr.tamu.edu/huangrh/Spring16/papers_course/matrix_factorization.pdf\">https://people.engr.tamu.edu/huangrh/Spring16/papers_course/matrix_factorization.pdf</a></li>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Example of the factorized graph</span><br><br>\n",
    "<img src=\"factors.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Graph setup</span>\n",
    "<br><br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.packages= [\"graphframes:graphframes:0.8.2-spark3.2-s_2.12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//GraphFrame imports\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.graphframes._\n",
    "\n",
    "\n",
    "//GraphX imports\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">GraphX or GraphFrames</span>\n",
    "<li>Both GraphX as well as GraphFrames have an implementation of the SVD++ algorithm</li>\n",
    "<li>But, I just can't figure out what exactly the GraphFrames version returns (no documentation!)</li>\n",
    "<li>So, we'll use GraphX for now!</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val people = Array((1L,\"John\"),\n",
    "                       (2L,\"Isabella\"),\n",
    "                       (3L,\"Qing\"),\n",
    "                       (4L,\"Bathsheba\"),\n",
    "                       (5L,\"Akaash\"),\n",
    "                       (6L,\"Pablo\"),\n",
    "                       (7L,\"Ludovica\"))\n",
    "\n",
    "val authors = Array((100L,\"Murakami\"),\n",
    "                   (101L,\"Adams\"),\n",
    "                   (103L,\"Liu\"),\n",
    "                   (104L,\"Pachinko\"),\n",
    "                   (105L,\"Kawabata\"),\n",
    "                   (106L,\"Hardy\"))\n",
    "\n",
    "val vertexArray = people++authors\n",
    "\n",
    "val edgeArray = Array(Edge(1L,100L,4.0),\n",
    "                     Edge(1L,103L,5.0),\n",
    "                     Edge(2L,104L,2.0),\n",
    "                     Edge(2L,106L,3.0),\n",
    "                     Edge(3L,101L,1.0),\n",
    "                     Edge(4L,105L,5.0),\n",
    "                     Edge(4L,104L,3.0),\n",
    "                     Edge(5L,100L,2.0),\n",
    "                     Edge(5L,105L,4.0),\n",
    "                     Edge(6L,101L,1.0),\n",
    "                     Edge(7L,103L,3.0),\n",
    "                     Edge(7L,105L,4.0))\n",
    "\n",
    "val vertexRDD: RDD[(Long, String)] = sc.parallelize(vertexArray)\n",
    "val edgeRDD: RDD[Edge[Double]] = sc.parallelize(edgeArray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size:xx-large\">Run SVD++</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Set the hyperparameters</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val config = new lib.SVDPlusPlus.Conf(rank=2, //number of latent factors\n",
    "                                    maxIters=10,\n",
    "                                    minVal=0,\n",
    "                                    maxVal=5,\n",
    "                                    gamma1=0.007, //hyper parameters controlling search\n",
    "                                    gamma2=0.007, //and preventing overfitting (see paper!)\n",
    "                                    gamma6=0.005,\n",
    "                                    gamma7=0.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">run the model</span>\n",
    "<li>the model returns a graph and the mean rating for the dataset</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "//val conf = new lib.SVDPlusPlus.Conf(2,10,0,5,0.007,0.007,0.005,0.015)\n",
    "val (g,mean) = lib.SVDPlusPlus.run(edgeRDD,config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Analyze results</span>\n",
    "<li>svd++ returns a graphx graph that corresponds to the original graph (13 vertices, 12 edges)</li>\n",
    "<li>The edges are the original edges</li>\n",
    "<li>The vertices are enhanced by an array that contains the vertex id along with 4 pieces of data</li>\n",
    "<li>The technical meaning of these things is best left to the linked paper but, roughly</li>\n",
    "<ul>\n",
    "    <li>the first is an arrays of factor loadings (user to latent factor or item to latent factor)</li>\n",
    "    <li>for users, the second is a composite of factor loadings and rating bias (the degree to which a user assigns ratings). For items, the second is a composite of factor loadings and rated bias (the degree to which an author is rated)</li>\n",
    "    <li>the third is a bias adjustment value that captures the user or item bias (i.e., if the user hates all authors then the bias would boost their ratings a bit and if an author is generally disliked then the bias would bring down their rating for a new user)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//results for user Ludovica\n",
    "g.vertices.filter(_._1==7L).collect()(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Results for author Adams\n",
    "g.vertices.filter(_._1==101L).collect()(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val u = 7L\n",
    "val i = 104L\n",
    "val user = g.vertices.filter(_._1 == u).collect()(0)._2 //This gives the user attributes from the graph\n",
    "val item = g.vertices.filter(_._1 == i).collect()(0)._2 //This gives the item attributes from the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vertices.filter(_._1 == u).collect()(0)._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user._3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item._3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item._1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user._2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item._1.zip(user._2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item._1.zip(user._2).map(x => x._1 * x._2).reduce(_ + _) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Using the graph, calculate the rating a user would give to an author</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(g:Graph[(Array[Double], Array[Double], Double, Double),Double],\n",
    "         mean:Double, u:Long, i:Long) = {\n",
    "  val user = g.vertices.filter(_._1 == u).collect()(0)._2 //This gives the user attributes from the graph\n",
    "  val item = g.vertices.filter(_._1 == i).collect()(0)._2 //This gives the item attributes from the graph\n",
    "  mean + user._3 + item._3 +  //user sentiment bias + item sentiment bias\n",
    "    item._2.zip(user._2).map(x => x._1 * x._2).reduce(_ + _) \n",
    "    //item._2 is the item to factors weights\n",
    "    //user._2 is the user to factor loadings\n",
    "    //We zip these together and add them up\n",
    "    //The entire total is then added to the mean rating from all users\n",
    "}\n",
    "\n",
    "pred(g, mean, 7L, 101L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(g:Graph[(Array[Double], Array[Double], Double, Double),Double],\n",
    "         mean:Double, u:Long, i:Long) = {\n",
    "  val user = g.vertices.filter(_._1 == u).collect()(0)._2 //This gives the user attributes from the graph\n",
    "  val item = g.vertices.filter(_._1 == i).collect()(0)._2 //This gives the item attributes from the graph\n",
    "  mean + user._3 + item._3 +  //user sentiment bias + item sentiment bias\n",
    "    item._2.zip(user._2).map(x => x._1 * x._2).reduce(_ + _) \n",
    "    //item._2 is the item to factors weights\n",
    "    //user._2 is the user to factor loadings\n",
    "    //We zip these together and add them up\n",
    "    //The entire total is then added to the mean rating from all users\n",
    "}\n",
    "\n",
    "pred(g, mean, 7L, 101L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">All ratings for a particular user</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val user = \"Ludovica\"\n",
    "val user_id = vertexRDD.filter(v => v._2==user).collect()(0)._1\n",
    "val all_preds = authors.map(l=>pred(g,mean,user_id,l._1)).zip(authors.map(l=>l._2))\n",
    "all_preds.sortBy(-_._1).foreach {l =>\n",
    "    println(user + \" rates \" + l._2.toString + \" \" + l._1.toString)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
