{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:red;font-size:60px\">Graph Algorithms</span>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>breadth-first search</li>\n",
    "<li>connected components</li>\n",
    "<li>label propagation</li>\n",
    "<li>shortest path</li>\n",
    "<li>triangle count</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Bulk Synchronous Parallel Model</span>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Both GraphX and GraphFrames use the \"Bulk Synchronous Parallel\" model of processing</li>\n",
    "<li>BSP model uses 3 supersteps for computation:</li>\n",
    "<ul>\n",
    "    <li>Do local computation concurrently for each vertex (or set of vertices)</li>\n",
    "    <li>Communicate results from one process to another directly (communication and message passing)</li>\n",
    "    <li>Synchronize activities using <span style=\"color:red\">barrier synchronization</span> (identify barrier tasks that must complete before subsequent processing is possible)</li>\n",
    "</ul>\n",
    "<br><br>\n",
    "<li>Comparison with MapReduce</li>\n",
    "<ul>\n",
    "    <li>in-memory state persistence between iterations</li>\n",
    "    <li>synchronization is restricted to state updates (reduced communication)</li>\n",
    "    <li>many iterations are possible (good for graphs where iterations may be a factor of the number of vertices) but each iteration is less intensive (since it only deals with updates)</li>\n",
    "    <li>message passing (between processors) rather than routing through a master node</li>\n",
    "    <li>each computation in a super step is independent (barrier synchronization ensures this)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.packages= [\"graphframes:graphframes:0.8.2-spark3.2-s_2.12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.56.179.196:4043\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1670867547507)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.graphframes._\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.graphframes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"social_graph2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexArray: Array[(Int, String, Int)] = Array((1,Alice,28), (2,Bob,27), (3,Charlie,65), (4,David,42), (5,Ed,55), (6,Fran,50), (7,Qing,27), (8,Sarika,78), (9,Olafson,17), (10,Birgit,33))\n",
       "edgeArray: Array[(Int, Int, Int)] = Array((2,1,7), (1,2,13), (2,4,2), (3,2,4), (3,6,3), (4,1,1), (5,2,2), (5,3,8), (5,6,3), (7,8,14), (7,9,2), (8,10,8), (9,10,6))\n",
       "vertex_df: org.apache.spark.sql.DataFrame = [id: int, name: string ... 1 more field]\n",
       "edge_df: org.apache.spark.sql.DataFrame = [src: int, dst: int ... 1 more field]\n",
       "g: org.graphframes.GraphFrame = GraphFrame(v:[id: int, name: string ... 1 more field], e:[src: int, dst: int ... 1 more field])\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vertexArray = Array(\n",
    "  (1, \"Alice\", 28),\n",
    "  (2, \"Bob\", 27),\n",
    "  (3, \"Charlie\", 65),\n",
    "  (4, \"David\", 42),\n",
    "  (5, \"Ed\", 55),\n",
    "  (6, \"Fran\", 50),\n",
    "    (7, \"Qing\",27),\n",
    "    (8, \"Sarika\",78),\n",
    "    (9, \"Olafson\",17),\n",
    "    (10, \"Birgit\",33)\n",
    ")\n",
    "\n",
    "val edgeArray = Array(\n",
    "  (2, 1, 7),\n",
    "  (1, 2, 13),\n",
    "  (2, 4, 2),\n",
    "  (3, 2, 4),\n",
    "  (3, 6, 3),\n",
    "  (4, 1, 1),\n",
    "  (5, 2, 2),\n",
    "  (5, 3, 8),\n",
    "  (5, 6, 3),\n",
    "    (7, 8, 14),\n",
    "    (7, 9, 2),\n",
    "    (8, 10, 8),\n",
    "    (9, 10, 6)\n",
    ")\n",
    "\n",
    "val vertex_df = spark.createDataFrame(vertexArray).toDF(\"id\",\"name\",\"age\")\n",
    "val edge_df = spark.createDataFrame(edgeArray).toDF(\"src\",\"dst\",\"attr\")\n",
    "\n",
    "val g = GraphFrame(vertex_df, edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Breadth-first search</span>\n",
    "<li>Shortest path between two nodes</li>\n",
    "<li>The shortest path can depend on node attributes</li>\n",
    "<li>Or we can find shortest paths from multiple nodes to multiple other nodes</li>\n",
    "<li>bfs computes path lengths based on the number of edges and does not use edge weights</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.bfs.fromExpr(\"name='Ed'\").toExpr(\"name='Alice'\").run().show\n",
    "g.bfs.fromExpr(\"name='Ed'\").toExpr(\"name='Alice'\").run().count\n",
    "g.bfs.fromExpr(\"age>45\").toExpr(\"age<45\").run().show\n",
    "g.bfs.fromExpr(\"name='Ed' or name='Bob'\").toExpr(\"name='Alice'\").run().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------------+---------+--------------+\n",
      "|       from|       e0|          v1|       e1|            to|\n",
      "+-----------+---------+------------+---------+--------------+\n",
      "|{5, Ed, 55}|{5, 2, 2}|{2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "+-----------+---------+------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.bfs.fromExpr(\"name='Ed'\").toExpr(\"name='Alice'\").run().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Long = 1\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.bfs.fromExpr(\"name='Ed'\").toExpr(\"name='Alice'\").run().count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------------+\n",
      "|            from|        e0|              to|\n",
      "+----------------+----------+----------------+\n",
      "|{3, Charlie, 65}| {3, 2, 4}|    {2, Bob, 27}|\n",
      "|     {5, Ed, 55}| {5, 2, 2}|    {2, Bob, 27}|\n",
      "| {8, Sarika, 78}|{8, 10, 8}|{10, Birgit, 33}|\n",
      "+----------------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.bfs.fromExpr(\"age>45\").toExpr(\"age<45\").run().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+--------------+\n",
      "|        from|       e0|            to|\n",
      "+------------+---------+--------------+\n",
      "|{2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "+------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.bfs.fromExpr(\"name='Ed' or name='Bob'\").toExpr(\"name='Alice'\").run().show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Connected components</span>\n",
    "\n",
    "<li>GraphFrames connected components function requires a <span style=\"color:red\">checkpoint</span> directory</li>\n",
    "<li>The algorithm returns a component number for each vertex</li>\n",
    "<li>The number of distinct component numbers is the number of components of the graph</li>\n",
    "<li><span style=\"color:red\">connectedComponents</span> returns a list of nodes with along with the component number</li>\n",
    "<li><span style=\"color:red\">stronglyConnectedComponents</span> returns a list of nodes with along with the component number for each <a href=\"https://en.wikipedia.org/wiki/Strongly_connected_component\">strongly connected component</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "directed graphs, a graph is said to be strongly connected if every vertex is reachable from every other vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setCheckpointDir(\"checkpoint\")\n",
    "val cc = g.connectedComponents.run()\n",
    "cc.show\n",
    "\n",
    "val result = g.stronglyConnectedComponents.maxIter(10).run()\n",
    "result.select(\"id\", \"component\").orderBy(\"component\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+---------+\n",
      "| id|   name|age|component|\n",
      "+---+-------+---+---------+\n",
      "|  1|  Alice| 28|        1|\n",
      "|  2|    Bob| 27|        1|\n",
      "|  3|Charlie| 65|        1|\n",
      "|  4|  David| 42|        1|\n",
      "|  5|     Ed| 55|        1|\n",
      "|  6|   Fran| 50|        1|\n",
      "|  7|   Qing| 27|        7|\n",
      "|  8| Sarika| 78|        7|\n",
      "|  9|Olafson| 17|        7|\n",
      "| 10| Birgit| 33|        7|\n",
      "+---+-------+---+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cc: org.apache.spark.sql.DataFrame = [id: int, name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.setCheckpointDir(\"checkpoint\")\n",
    "val cc = g.connectedComponents.run()\n",
    "cc.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|component|\n",
      "+---+---------+\n",
      "|  2|        1|\n",
      "|  1|        1|\n",
      "|  4|        1|\n",
      "|  3|        3|\n",
      "|  5|        5|\n",
      "|  6|        6|\n",
      "|  7|        7|\n",
      "|  8|        8|\n",
      "|  9|        9|\n",
      "| 10|       10|\n",
      "+---+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result: org.apache.spark.sql.DataFrame = [id: int, name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result = g.stronglyConnectedComponents.maxIter(10).run()\n",
    "result.select(\"id\", \"component\").orderBy(\"component\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Label propagation</span>\n",
    "<li>\n",
    "<li>The label propagation algorithm is a clustering algorithm</li>\n",
    "<li>Finds \"similar\" nodes in the graph</li>\n",
    "<li>the algorithm is iterative but converges very quickly</li>\n",
    "<li>Roughly:</li>\n",
    "<ul>\n",
    "    <li>assign labels randomly to vertices (depending on the size of the graph, this could be to all nodes or just a few)</li>\n",
    "    <li>update labels based on the frequency of labels in adjacent nodes</li>\n",
    "    <li>repeat updates</li>\n",
    "    <li>stop after n iterations</li>\n",
    "    <li>label propagation is done on the canonical undirected graph</li>\n",
    "</ul>\n",
    "<li>Label propagation is used to group nodes in very large graphs - mostly because an exhaustive grouping is computationally infeasible</li>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|label|\n",
      "+---+-----+\n",
      "|  8|    7|\n",
      "|  1|    2|\n",
      "|  9|    7|\n",
      "| 10|    8|\n",
      "|  2|    2|\n",
      "|  3|    2|\n",
      "|  4|    2|\n",
      "|  5|    2|\n",
      "|  6|    2|\n",
      "|  7|    8|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result: org.apache.spark.sql.DataFrame = [id: int, name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result = g.labelPropagation.maxIter(3).run()\n",
    "result.select(\"id\", \"label\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Shortest path</span>\n",
    "<li>Compute the shortest path (length) from each vertex to a set of \"landmark\" vertices </li>\n",
    "<li>Unfortunately, the shortest path algorithm needs vertex ids to be strings, so we'll convert them to strings!</li>\n",
    "<li>In the example below, we compute the shortest path from every vertex to vertices 3, 6, and 10</li>\n",
    "<li>For example, if a company has several factories and several distribution warehouses, it might want to find the shortest path from each factory to each warehouse</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexArray: Array[(String, String, Int)] = Array((1,Alice,28), (2,Bob,27), (3,Charlie,65), (4,David,42), (5,Ed,55), (6,Fran,50), (7,Qing,27), (8,Sarika,78), (9,Olafson,17), (10,Birgit,33))\n",
       "edgeArray: Array[(String, String, Int)] = Array((2,1,7), (1,2,13), (2,4,2), (3,2,4), (3,6,3), (4,1,1), (5,2,2), (5,3,8), (5,6,3), (7,8,14), (7,9,2), (8,10,8), (9,10,6))\n",
       "vertex_df: org.apache.spark.sql.DataFrame = [id: string, name: string ... 1 more field]\n",
       "edge_df: org.apache.spark.sql.DataFrame = [src: string, dst: string ... 1 more field]\n",
       "g: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vertexArray = Array(\n",
    "  (1, \"Alice\", 28),\n",
    "  (2, \"Bob\", 27),\n",
    "  (3, \"Charlie\", 65),\n",
    "  (4, \"David\", 42),\n",
    "  (5, \"Ed\", 55),\n",
    "  (6, \"Fran\", 50),\n",
    "    (7, \"Qing\",27),\n",
    "    (8, \"Sarika\",78),\n",
    "    (9, \"Olafson\",17),\n",
    "    (10, \"Birgit\",33)\n",
    ").map(l=>(l._1.toString,l._2,l._3))\n",
    "\n",
    "val edgeArray = Array(\n",
    "  (2, 1, 7),\n",
    "  (1, 2, 13),\n",
    "  (2, 4, 2),\n",
    "  (3, 2, 4),\n",
    "  (3, 6, 3),\n",
    "  (4, 1, 1),\n",
    "  (5, 2, 2),\n",
    "  (5, 3, 8),\n",
    "  (5, 6, 3),\n",
    "    (7, 8, 14),\n",
    "    (7, 9, 2),\n",
    "    (8, 10, 8),\n",
    "    (9, 10, 6)\n",
    ").map(l=>(l._1.toString,l._2.toString,l._3))\n",
    "\n",
    "val vertex_df = spark.createDataFrame(vertexArray).toDF(\"id\",\"name\",\"age\")\n",
    "val edge_df = spark.createDataFrame(edgeArray).toDF(\"src\",\"dst\",\"attr\")\n",
    "\n",
    "val g = GraphFrame(vertex_df, edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----------------+\n",
      "| id|   name|age|       distances|\n",
      "+---+-------+---+----------------+\n",
      "|  1|  Alice| 28|              {}|\n",
      "|  5|     Ed| 55|{6 -> 1, 3 -> 1}|\n",
      "|  2|    Bob| 27|              {}|\n",
      "|  8| Sarika| 78|       {10 -> 1}|\n",
      "|  4|  David| 42|              {}|\n",
      "|  3|Charlie| 65|{6 -> 1, 3 -> 0}|\n",
      "|  6|   Fran| 50|        {6 -> 0}|\n",
      "| 10| Birgit| 33|       {10 -> 0}|\n",
      "|  9|Olafson| 17|       {10 -> 1}|\n",
      "|  7|   Qing| 27|       {10 -> 2}|\n",
      "+---+-------+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.shortestPaths.landmarks(Seq(\"3\",\"6\",\"10\")).run().show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Page Rank</span>\n",
    "<br><br>\n",
    "<li>An implementation of Google's page ranking algorithm</li>\n",
    "<li>Web pages = nodes; links = edges</li>\n",
    "<li>See <a href=\"https://en.wikipedia.org/wiki/PageRank\">wikipedia</a> for details but the rough idea is:</li>\n",
    "<ul>\n",
    "    <li>the rank of a page is higher if it has more incoming links</li>\n",
    "    <li>the rank of a page is higher if the pages that link to it have higher ranks</li>\n",
    "</ul>\n",
    "<li>pagerank takes three arguments</li>\n",
    "<ul>\n",
    "    <li><span style=\"color:red\">resetProbability</span>: random walk reset probability (the probability that a page will move to a random page in the network rather than follow a link </li>\n",
    "    <li><span style=\"color:red\">tol</span>: algorithm stops when it converges to the tol level  </li>\n",
    "    <li><span style=\"color:red\">maxIter</span>:  stop after the specified number of iterations</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val results = g.pageRank.resetProbability(0.15).maxIter(10).run()\n",
    "// val ranks = g.pageRank.resetProbability(0.15).tol(0.0001).run()\n",
    "results.vertices.show\n",
    "\n",
    "val results = g.parallelPersonalizedPageRank.resetProbability(0.01).maxIter(100)\n",
    "            .sourceIds(Array(\"1\",\"2\")).run()\n",
    "results.vertices.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-------------------+\n",
      "| id|   name|age|           pagerank|\n",
      "+---+-------+---+-------------------+\n",
      "|  1|  Alice| 28|  2.681863350565778|\n",
      "|  5|     Ed| 55| 0.2709323459354504|\n",
      "|  2|    Bob| 27|  2.779774156609249|\n",
      "|  8| Sarika| 78|0.38607859295801683|\n",
      "|  4|  David| 42| 1.4539106228273422|\n",
      "|  3|Charlie| 65|0.34769651061716134|\n",
      "|  6|   Fran| 50|0.49546752762945484|\n",
      "| 10| Birgit| 33| 0.9272659539640791|\n",
      "|  9|Olafson| 17|0.38607859295801683|\n",
      "|  7|   Qing| 27| 0.2709323459354504|\n",
      "+---+-------+---+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "results: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 2 more fields], e:[src: string, dst: string ... 2 more fields])\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = g.pageRank.resetProbability(0.15).maxIter(10).run()\n",
    "// val ranks = g.pageRank.resetProbability(0.15).tol(0.0001).run()\n",
    "results.vertices.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">parallelized version of page rank</span>\n",
    "<li>specify a list of verttices from which to run pagerank in parallel</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+---------------------------------------------------+\n",
      "|id |name   |age|pageranks                                          |\n",
      "+---+-------+---+---------------------------------------------------+\n",
      "|1  |Alice  |28 |(2,[0,1],[0.40321767706296224,0.39655999652854973])|\n",
      "|5  |Ed     |55 |(2,[0,1],[0.0,0.0])                                |\n",
      "|2  |Bob    |27 |(2,[0,1],[0.39918550029233296,0.4039384831710437]) |\n",
      "|8  |Sarika |78 |(2,[0,1],[0.0,0.0])                                |\n",
      "|4  |David  |42 |(2,[0,1],[0.19759682264470482,0.19950152030040658])|\n",
      "|3  |Charlie|65 |(2,[0,1],[0.0,0.0])                                |\n",
      "|6  |Fran   |50 |(2,[0,1],[0.0,0.0])                                |\n",
      "|10 |Birgit |33 |(2,[0,1],[0.0,0.0])                                |\n",
      "|9  |Olafson|17 |(2,[0,1],[0.0,0.0])                                |\n",
      "|7  |Qing   |27 |(2,[0,1],[0.0,0.0])                                |\n",
      "+---+-------+---+---------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "results: org.graphframes.GraphFrame = GraphFrame(v:[id: string, name: string ... 2 more fields], e:[src: string, dst: string ... 2 more fields])\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = g.parallelPersonalizedPageRank.resetProbability(0.01).maxIter(100).sourceIds(Array(\"1\",\"2\")).run()\n",
    "results.vertices.show(false)\n",
    "// .sourceIds(Array(\"1\",\"2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">triangle count</span>\n",
    "<li>the number of triangles that each vertice belongs to</li>\n",
    "<li>for example, Bob belongs to two triangles: (Bob, David, Alice) and (Bob, Charlie, Ed)</li>\n",
    "<li>triangles assume an undirected graph</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+---+\n",
      "|count| id|   name|age|\n",
      "+-----+---+-------+---+\n",
      "|    1|  1|  Alice| 28|\n",
      "|    2|  2|    Bob| 27|\n",
      "|    2|  3|Charlie| 65|\n",
      "|    2|  5|     Ed| 55|\n",
      "|    1|  4|  David| 42|\n",
      "|    1|  6|   Fran| 50|\n",
      "|    0|  7|   Qing| 27|\n",
      "|    0|  8| Sarika| 78|\n",
      "|    0|  9|Olafson| 17|\n",
      "|    0| 10| Birgit| 33|\n",
      "+-----+---+-------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [count: bigint, id: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = g.triangleCount.run()\n",
    "results.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Clustering coefficient using triangle count</span>\n",
    "<li>clustering coefficient = number of triangles a vertex belongs to divided by the number of possible triangles</li>\n",
    "<li>for example, Alice belongs to 1 triangle (Alice, Bob, David) and, since she has only two adjacent vertices, the number of possible triangles is also 1. Alice's clustering coefficient is 1/1 = 1.0</li>\n",
    "<li>Bob belongs to two triangles. The possible triangles are: \n",
    "    <ul>\n",
    "        <li>(Bob, David, Alice)</li>\n",
    "        <li>(Bob, David, Charlie)</li>\n",
    "        <li>(Bob, Alice, Charlie)</li>\n",
    "        <li>(Bob, David, Ed)</li>\n",
    "        <li>(Bob, Alice, Ed)</li>\n",
    "        <li>(Bob, Charlie, Ed)</li>\n",
    "    </ul>\n",
    "<li>thus, Bob's clustering coefficient is 2/6 = 0.33</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_undirected_graph: (g: org.graphframes.GraphFrame)org.graphframes.GraphFrame\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Copied from previous notebook\n",
    "def make_undirected_graph(g: GraphFrame) = {\n",
    "    val u_edge_df = g.find(\"(a)-[]->(b)\")\n",
    "        .select($\"a.id\".as(\"src\"),$\"b.id\".as(\"dst\"))\n",
    "        .withColumn(\"swap\",when(col(\"src\")<col(\"dst\"),col(\"dst\")))\n",
    "        .withColumn(\"dst\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"src\"))\n",
    "                    .otherwise(col(\"dst\")))\n",
    "        .withColumn(\"src\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"swap\"))\n",
    "                   .otherwise(col(\"src\")))\n",
    "        .drop(col(\"swap\"))\n",
    "        .distinct\n",
    "    val u_vertices_df = g.vertices\n",
    "    val u_g = GraphFrame(u_vertices_df,u_edge_df)    \n",
    "    u_g\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|             coeff|\n",
      "+---+------------------+\n",
      "|  1|               1.0|\n",
      "|  2|0.3333333333333333|\n",
      "|  3|0.6666666666666666|\n",
      "|  5|0.6666666666666666|\n",
      "|  4|               1.0|\n",
      "|  6|               1.0|\n",
      "|  7|               0.0|\n",
      "|  8|               0.0|\n",
      "|  9|               0.0|\n",
      "| 10|               0.0|\n",
      "+---+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "triangles: org.apache.spark.sql.DataFrame = [count: bigint, t_id: string ... 2 more fields]\n",
       "degrees: org.apache.spark.sql.DataFrame = [id: string, degree: int]\n",
       "possible: org.apache.spark.sql.DataFrame = [id: string, degree: int ... 1 more field]\n",
       "joined: org.apache.spark.sql.DataFrame = [t_id: string, count: bigint ... 3 more fields]\n",
       "coeff: org.apache.spark.sql.DataFrame = [t_id: string, count: bigint ... 4 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val triangles = g.triangleCount.run().withColumnRenamed(\"id\",\"t_id\") \n",
    "//Get the number of triangles each vertex belongs to\n",
    "val degrees = make_undirected_graph(g).degrees \n",
    "//Get the number of adjacent vertices for each vertex\n",
    "val possible = degrees.withColumn(\"possible\",col(\"degree\")*(col(\"degree\")-1)/lit(2)) \n",
    "//Calculate possible triangles\n",
    "val joined = triangles.select(\"t_id\",\"count\").join(possible,triangles(\"t_id\")===possible(\"id\")) \n",
    "val coeff = joined.withColumn(\"coeff\",col(\"count\")/col(\"possible\"))\n",
    "coeff.select(\"id\",\"coeff\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+\n",
      "| id|degree|possible|\n",
      "+---+------+--------+\n",
      "|  7|     2|     1.0|\n",
      "|  3|     3|     3.0|\n",
      "|  8|     2|     1.0|\n",
      "|  5|     3|     3.0|\n",
      "|  6|     2|     1.0|\n",
      "|  9|     2|     1.0|\n",
      "|  1|     2|     1.0|\n",
      "| 10|     2|     1.0|\n",
      "|  4|     2|     1.0|\n",
      "|  2|     4|     6.0|\n",
      "+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "degrees.withColumn(\"possible\",col(\"degree\")*(col(\"degree\")-1)/lit(2)).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+---+\n",
      "|count|t_id|   name|age|\n",
      "+-----+----+-------+---+\n",
      "|    1|   1|  Alice| 28|\n",
      "|    2|   2|    Bob| 27|\n",
      "|    2|   3|Charlie| 65|\n",
      "|    2|   5|     Ed| 55|\n",
      "|    1|   4|  David| 42|\n",
      "|    1|   6|   Fran| 50|\n",
      "|    0|   7|   Qing| 27|\n",
      "|    0|   8| Sarika| 78|\n",
      "|    0|   9|Olafson| 17|\n",
      "|    0|  10| Birgit| 33|\n",
      "+-----+----+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.triangleCount.run().withColumnRenamed(\"id\",\"t_id\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">aggregateMessages</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Neighborhood aggregation function through messaging</li>\n",
    "<li>Messages</li>\n",
    "<ul>\n",
    "    <li>source data (e.g., AggregateMessages.src(\"age\"))</li>\n",
    "    <li>destination data (e.g., AggregateMessages.dst(\"age))</li>\n",
    "    <li>edge data (e.g., AggregateMessages.edge(\"attr\")</li> \n",
    "    <li>A message is sent from each vertex either from a src to a dst (sendToDst) or from a dst to a source (sendToSrc)</li>\n",
    "    <li>A function then processes the received message (agg)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions\n",
    "import org.graphframes.lib.AggregateMessages\n",
    "g.aggregateMessages\n",
    "    .sendToDst(AggregateMessages.edge(\"attr\")) \n",
    "    //Send the edge attr to value to the destination\n",
    "    .agg(sum(AggregateMessages.msg).as(\"alllikes\")).show \n",
    "    //Aggregate messages by summing them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions\n",
       "import org.graphframes.lib.AggregateMessages\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions\n",
    "import org.graphframes.lib.AggregateMessages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Calculate total incoming likes for every node</span>\n",
    "<li>For example, Bob has 3 incoming edges, each with attr values 13, 2, 4</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|alllikes|\n",
      "+---+--------+\n",
      "|  1|       8|\n",
      "|  4|       2|\n",
      "|  2|      19|\n",
      "|  6|       6|\n",
      "|  3|       8|\n",
      "|  9|       2|\n",
      "|  8|      14|\n",
      "| 10|      14|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.aggregateMessages\n",
    "    .sendToDst(AggregateMessages.edge(\"attr\")) //Send the edge attr to value to the destination\n",
    "    .agg(sum(AggregateMessages.msg).as(\"alllikes\")).show //Aggregate messages by summing them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Try this: Calculate total outgoing likes for each person</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|alllikes|\n",
      "+---+--------+\n",
      "|  2|       9|\n",
      "|  1|      13|\n",
      "|  3|       7|\n",
      "|  4|       1|\n",
      "|  5|      13|\n",
      "|  7|      16|\n",
      "|  9|       6|\n",
      "|  8|       8|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.aggregateMessages\n",
    "    .sendToSrc(AggregateMessages.edge(\"attr\")) //Send the edge attr to value to the destination\n",
    "    .agg(sum(AggregateMessages.msg).as(\"alllikes\")) //Aggregate messages by summing them up\n",
    "    .show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">for each person, who likes them the most and how much?</span>\n",
    "<li>This is going to be embarrassingly complicated!</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_df: org.apache.spark.sql.DataFrame = [id: int, maxval: int]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val max_df = g.aggregateMessages\n",
    "    .sendToDst(AggregateMessages.edge(\"attr\"))\n",
    "    .agg(max(AggregateMessages.msg))\n",
    "    .withColumnRenamed(\"max(MSG)\",\"maxval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|maxval|\n",
      "+---+------+\n",
      "|  1|     7|\n",
      "|  4|     2|\n",
      "|  2|    13|\n",
      "|  6|     3|\n",
      "|  3|     8|\n",
      "|  9|     2|\n",
      "|  8|    14|\n",
      "| 10|     8|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- maxval: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df.createOrReplaceTempView(\"max_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(maxval)|\n",
      "+-----------+\n",
      "|         14|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select max(maxval) from max_db\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|maxval|\n",
      "+---+------+\n",
      "|  8|    14|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id, maxval from max_db where maxval = (select max(maxval) from max_db)\").show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
