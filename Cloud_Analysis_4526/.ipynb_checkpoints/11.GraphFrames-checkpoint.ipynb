{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:red;font-size:60px\">Graphs</span>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:40px\">GraphX</span>\n",
    "<br><br><br>\n",
    "<div style=\"font-size:large\">\n",
    "\n",
    "\n",
    "<li>RDD based graph library</li>\n",
    "<li>native to Spark</li>\n",
    "<li>not available in PySpark (only Scala API)</li>\n",
    "<li>require strong type data</li>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:40px\">GraphFrames</span>\n",
    "<br><br><br>\n",
    "\n",
    "<div style=\"font-size:large\">\n",
    "    <li>GraphFrames is a dataframe based API for graphs</li>\n",
    "    <li>Since it is still in the prototype stage (not native to Spark), you'll need to load external packages</li>\n",
    "    <li>Unlike GraphX, the RDD based graph analytics package on Spark, GraphFrames has a PySpark API</li>\n",
    "    <li>Graphframes provides a set of <span style=\"color:red\">graph algorithms</span> and <span style=\"color:red\">motifs</span> (and, of course, <span style=\"color:red\">dataframe queries</span> on a graph)</li>\n",
    "    <li>SQL bassed</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Installing packages in spylon-kernel</span>\n",
    "<br><br>\n",
    "<li>packages need to be installed at launch time</li>\n",
    "<li>they can either be local JARs (Java Archives) or sitting on the web </li>\n",
    "<li>In spylon-kernel, you can initialize a spark session and add packages (on a web archive) using the <span style=\"color:blue\">launcher.packages</span> command</li>\n",
    "<li><b>structure of launcher packages</b>: archive-name:package-name:package-version</li>\n",
    "<li><b>specifying the package-version</b>: version_number-spark_version-scala_version</li>\n",
    "<li>Example:</li>\n",
    "<ul><li>the archive is <span style=\"color:blue\">graphframes</span></li>\n",
    "    <li>the package is <span style=\"color:blue\">graphframes</span></li>\n",
    "    <li>graphframes version is 0.8.2 (that's the version for spark 3.2). See <a href=\"https://spark-packages.org/package/graphframes/graphframes\">https://spark-packages.org/package/graphframes/graphframes</a> for other versions</li>\n",
    "    <li>The Scala version is 2.12 </li>\n",
    "    <li>Therefore the package spec is <i>\"graphframes:graphframes:0.8.2-spark3.2-s_2.12\"</i></li>\n",
    "</ul>\n",
    "<li><b>Note:</b></li> You can check your scala and spark versions using:\n",
    "<ul>\n",
    "    <li><span style=\"color:green\">util.Properties.versionString</span> to get the scala version</li>\n",
    "    <li><span style=\"color:green\">spark.version</span> to get the spark version</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "java virtual machine -> scala -> spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.packages= [\"graphframes:graphframes:0.8.2-spark3.2-s_2.12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.56.177.230:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1668111007920)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "res0: String = 3.3.0\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: String = version 2.12.15\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.Properties.versionString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "<span style=\"color:green;font-size:xx-large\">If package installation fails</span>\n",
    "<br>\n",
    "You'll know if package installation has failed (hopefully, that won't happen but just in case) if you see a lot of pink. \n",
    "<li> If you see the following error message: <span style=\"color:red\">Exception: Java gateway process exited before sending the driver its port number</span>:\n",
    "    <ul>\n",
    "        <li>Check your java version (see <a href=\"https://www.java.com/en/download/help/version_manual.html\">how to check your java version</a>. If your running version is not 1.8 or 1.11, you have a problem</li>\n",
    "        <li>Check the value of the JAVA_HOME environmental variable (on a mac: <span style=\"color:blue\">echo \\$JAVA_HOME</span>, on windows, you'll need to go into your settings and look for environmental variables). If it is empty, try setting it using <span style=\"color:blue\">export JAVA_HOME=\\$(/usr/libexec/java_home -v 1.8) (or the appropriate 1.11 version)</span> (I'm not sure how to do this on windows, sorry. Hopefully it won't be an issue!</li>\n",
    "    </ul>\n",
    "    <li>If you get some other error, or if the above does not work, try downloading the jar from <a href=\"https://spark-packages.org/package/graphframes/graphframes\">https://spark-packages.org/package/graphframes/graphframes</a>. Then copy the jar into your spark jar repository. Your jar repository is at SPARK_HOME/jars and you can drop the file in there. Then, replace <span style=\"color:red\">launcher.packages</span> by <span style=\"color:red\">launcher.jars</span> and you should be good (remember to restart the kernel before doing this)</li>\n",
    "    <li><b>Windows users</b>: If you get the error  <span style=\"color:red\">fail to locate wintuils ...\"</span>. Go to <a href=\"https://kontext.tech/column/hadoop/825/hadoop-331-winutils\">https://kontext.tech/column/hadoop/825/hadoop-331-winutils</a> and follow the instructions to download winutils.exe. Create the directory C:\\winutils, install winutils.exe in this directory, and then create a new system variable called HADOOP_HOME with the value C:\\winutils and add %HADOOP_HOME%bin to your system PATH variable</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Imports</span>\n",
    "<li>Since GraphFrames is a dataframe based package, we also need to import sql packages</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.graphframes._\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.graphframes._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both in Graphx and Graphframe, it is directed graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Creating a graph</span>\n",
    "<li>Create a dataframe of vertices and a dataframe of edges</li>\n",
    "<li>Create a graphframe using the vertices and edges</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"social_graph2.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexArray: Array[(Int, String, Int)] = Array((1,Alice,28), (2,Bob,27), (3,Charlie,65), (4,David,42), (5,Ed,55), (6,Fran,50), (7,Qing,27), (8,Sarika,78), (9,Olafson,17), (10,Birgit,33))\n",
       "edgeArray: Array[(Int, Int, Int)] = Array((2,1,7), (1,2,13), (2,4,2), (3,2,4), (3,6,3), (4,1,1), (5,2,2), (5,3,8), (5,6,3), (7,8,14), (7,9,2), (8,10,8), (9,10,6))\n",
       "vertex_df: org.apache.spark.sql.DataFrame = [id: int, name: string ... 1 more field]\n",
       "edge_df: org.apache.spark.sql.DataFrame = [src: int, dst: int ... 1 more field]\n",
       "g: org.graphframes.GraphFrame = GraphFrame(v:[id: int, name: string ... 1 more field], e:[src: int, dst: int ... 1 more field])\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vertexArray = Array(\n",
    "  (1, \"Alice\", 28),\n",
    "  (2, \"Bob\", 27),\n",
    "  (3, \"Charlie\", 65),\n",
    "  (4, \"David\", 42),\n",
    "  (5, \"Ed\", 55),\n",
    "  (6, \"Fran\", 50),\n",
    "    (7, \"Qing\",27),\n",
    "    (8, \"Sarika\",78),\n",
    "    (9, \"Olafson\",17),\n",
    "    (10, \"Birgit\",33)\n",
    ")\n",
    "\n",
    "val edgeArray = Array(\n",
    "  (2, 1, 7),\n",
    "  (1, 2, 13),\n",
    "  (2, 4, 2),\n",
    "  (3, 2, 4),\n",
    "  (3, 6, 3),\n",
    "  (4, 1, 1),\n",
    "  (5, 2, 2),\n",
    "  (5, 3, 8),\n",
    "  (5, 6, 3),\n",
    "    (7, 8, 14),\n",
    "    (7, 9, 2),\n",
    "    (8, 10, 8),\n",
    "    (9, 10, 6)\n",
    ")\n",
    "\n",
    "val vertex_df = spark.createDataFrame(vertexArray).toDF(\"id\",\"name\",\"age\")\n",
    "val edge_df = spark.createDataFrame(edgeArray).toDF(\"src\",\"dst\",\"attr\")\n",
    "\n",
    "val g = GraphFrame(vertex_df, edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertex_df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  1|  Alice| 28|\n",
      "|  2|    Bob| 27|\n",
      "|  3|Charlie| 65|\n",
      "|  4|  David| 42|\n",
      "|  5|     Ed| 55|\n",
      "|  6|   Fran| 50|\n",
      "|  7|   Qing| 27|\n",
      "|  8| Sarika| 78|\n",
      "|  9|Olafson| 17|\n",
      "| 10| Birgit| 33|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertex_df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "<span style=\"color:green;font-size:xx-large\">Basic queries</span>\n",
    "<li>Queries return dataframes</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>inDegrees</b>: The number of incoming edges at each node</li>\n",
    "<li><b>outDegrees</b>: The number of outgoing edges at each node</li>\n",
    "<li><b>degrees</b>: incoming + outgoing edges at each node</li>\n",
    "<li>Generally, functions on a graphframe will return a dataframe (or another graphframe)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  1|       2|\n",
      "|  4|       1|\n",
      "|  2|       3|\n",
      "|  6|       2|\n",
      "|  3|       1|\n",
      "|  9|       1|\n",
      "|  8|       1|\n",
      "| 10|       2|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.inDegrees.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: org.apache.spark.sql.DataFrame = [id: int, inDegree: int]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.inDegrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|outDegree|\n",
      "+---+---------+\n",
      "|  2|        2|\n",
      "|  1|        1|\n",
      "|  3|        2|\n",
      "|  4|        1|\n",
      "|  5|        3|\n",
      "|  7|        2|\n",
      "|  9|        1|\n",
      "|  8|        1|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.outDegrees.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|degree|\n",
      "+---+------+\n",
      "|  1|     3|\n",
      "|  2|     5|\n",
      "|  4|     2|\n",
      "|  3|     3|\n",
      "|  6|     2|\n",
      "|  5|     3|\n",
      "|  9|     2|\n",
      "|  8|     2|\n",
      "|  7|     2|\n",
      "| 10|     2|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.degrees.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>g.vertices and g.edges return a dataframe</li>\n",
    "<li>and all dataframe functions will work</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  1|  Alice| 28|\n",
      "|  2|    Bob| 27|\n",
      "|  3|Charlie| 65|\n",
      "|  4|  David| 42|\n",
      "|  5|     Ed| 55|\n",
      "|  6|   Fran| 50|\n",
      "|  7|   Qing| 27|\n",
      "|  8| Sarika| 78|\n",
      "|  9|Olafson| 17|\n",
      "| 10| Birgit| 33|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.vertices.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|src|dst|attr|\n",
      "+---+---+----+\n",
      "|  2|  1|   7|\n",
      "|  1|  2|  13|\n",
      "|  2|  4|   2|\n",
      "|  3|  2|   4|\n",
      "|  3|  6|   3|\n",
      "|  4|  1|   1|\n",
      "|  5|  2|   2|\n",
      "|  5|  3|   8|\n",
      "|  5|  6|   3|\n",
      "|  7|  8|  14|\n",
      "|  7|  9|   2|\n",
      "|  8| 10|   8|\n",
      "|  9| 10|   6|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.edges.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  3|Charlie| 65|\n",
      "|  4|  David| 42|\n",
      "|  5|     Ed| 55|\n",
      "|  6|   Fran| 50|\n",
      "|  8| Sarika| 78|\n",
      "| 10| Birgit| 33|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.vertices.filter(\"age>30\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<span style=\"color:green;font-size:xx-large\">Advanced querying: Graph motifs</span>\n",
    "<li>A graph <span style=\"color:red\">motif</span> is a recurring pattern of interconnections between nodes in a graph. Motifs are used to find interesting subgraphs (i.e., the subgraph that satisfies the pattern defined by a motif)</li>\n",
    "<li>Example, the subgraph of vertices that are connected with each other in both directions (Alice and Bob in our example)</li>\n",
    "<li>A <span style=\"color:red\">triplet</span> is a set containing two nodes and an edge that connects them</li>\n",
    "<li>Motifs are constructed by specifying triplet patterns (the \"pattern of interconnections\")</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Motifs</span>\n",
    "<li>Motifs are constructed by specifying triplet patterns (vertex,edge,vertex) sequences</li>\n",
    "<li>A motif can contain multiple such sequences</li>\n",
    "<li>Nodes are represented by parentheses while edges by square brackets</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<span style=\"color:blue;font-size:large\">Subgraph of vertices that are connected to each other in both directions</span>\n",
    "<li>The first triplet matches with any pair of nodes (a) (b) that are connected with a directed edge from (a) to (b)</li>\n",
    "<li>Every pair of nodes with a directed edge is a candidate for this triplet</li>\n",
    "<li>The second triplet uses the results of the first triplet, matches a to (a) and b to (b) and then looks for edges from (b) to (a)</li>\n",
    "<li>The values of a, b, are set by the first pattern</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------+----------+\n",
      "|             a|         e|             b|        e2|\n",
      "+--------------+----------+--------------+----------+\n",
      "|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 1, 7}|\n",
      "|  {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|{1, 2, 13}|\n",
      "+--------------+----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Subgraph of vertices that are connected with each other in both directions\n",
    "\n",
    "g.find(\"(a)-[e]->(b); (b)-[e2]->(a)\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">subgraph that contains triangles</span>\n",
    "<br>\n",
    "<li>Notice the patttern. (a) -> (b); (b) -> (c); (c) -> (a)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------+----------+--------------+----------+\n",
      "|             a|         e|             b|        e2|             c|        e3|\n",
      "+--------------+----------+--------------+----------+--------------+----------+\n",
      "|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|\n",
      "|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|{1, 2, 13}|\n",
      "|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 4, 2}|\n",
      "+--------------+----------+--------------+----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[e]->(b); (b)-[e2]->(c); (c)-[e3]->(a)\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lecture_graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Example: Get all the edges in the graph and the destination nodes</li>\n",
    "<li><b>Anonymous edges and vertices</b>: Omitting the name of an edge or vertice makes it anonymous. Effectively, that means it will not show up in the output dataframe and you cannot match it in a pattern</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|         e|               c|\n",
      "+----------+----------------+\n",
      "| {4, 1, 1}|  {1, Alice, 28}|\n",
      "| {2, 1, 7}|  {1, Alice, 28}|\n",
      "| {5, 2, 2}|    {2, Bob, 27}|\n",
      "| {3, 2, 4}|    {2, Bob, 27}|\n",
      "|{1, 2, 13}|    {2, Bob, 27}|\n",
      "| {5, 3, 8}|{3, Charlie, 65}|\n",
      "| {2, 4, 2}|  {4, David, 42}|\n",
      "| {5, 6, 3}|   {6, Fran, 50}|\n",
      "| {3, 6, 3}|   {6, Fran, 50}|\n",
      "|{7, 8, 14}| {8, Sarika, 78}|\n",
      "| {7, 9, 2}|{9, Olafson, 17}|\n",
      "|{9, 10, 6}|{10, Birgit, 33}|\n",
      "|{8, 10, 8}|{10, Birgit, 33}|\n",
      "+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"()-[e]->(c)\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Negation</span>\n",
    "<li>The ! operator indicates negation</li>\n",
    "<li>Example: Find all pairs of nodes that are connected but not connected in both direction</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|               a|               b|\n",
      "+----------------+----------------+\n",
      "| {8, Sarika, 78}|{10, Birgit, 33}|\n",
      "|     {5, Ed, 55}|    {2, Bob, 27}|\n",
      "|     {5, Ed, 55}|   {6, Fran, 50}|\n",
      "|  {4, David, 42}|  {1, Alice, 28}|\n",
      "|   {7, Qing, 27}| {8, Sarika, 78}|\n",
      "|     {5, Ed, 55}|{3, Charlie, 65}|\n",
      "|   {7, Qing, 27}|{9, Olafson, 17}|\n",
      "|{3, Charlie, 65}|   {6, Fran, 50}|\n",
      "|{3, Charlie, 65}|    {2, Bob, 27}|\n",
      "|{9, Olafson, 17}|{10, Birgit, 33}|\n",
      "|    {2, Bob, 27}|  {4, David, 42}|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find( \"(a)-[]->(b); !(b)-[]->(a)\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">paths of length 2 that are not cycles</span>\n",
    "<li>Get the starting and ending nodes of all paths of length two in the graph. No paths to a node itself are allowed</li>\n",
    "<li>Example: Alice - Bob - David has a path of length 2 so you should return Alice as the starting node and David as the ending node</li>\n",
    "<li>The graphframe <span style=\"color:red\">find</span> function gets sets of three nodes using a motif</li>\n",
    "<li>The dataframe <span style=\"color:red\">filter</span> function removes sets where the first and third nodes are the same</li>\n",
    "<li>Rename the columns to <span style=\"color:blue\">src</span> and <span style=\"color:blue\">dst</span> using <span style=\"color:red\">toDF</span></li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//All paths of length 2 from a to c where a and c are distinct (not equal)\n",
    "g.find(\"(a)-[]->(b);(b)-[]->(c)\").filter(\"a.id != c.id\").show\n",
    "//dataframe is quick than graphframe at most cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----------------+\n",
      "|               a|               b|               c|\n",
      "+----------------+----------------+----------------+\n",
      "|  {1, Alice, 28}|    {2, Bob, 27}|  {4, David, 42}|\n",
      "|  {1, Alice, 28}|    {2, Bob, 27}|  {1, Alice, 28}|\n",
      "|    {2, Bob, 27}|  {4, David, 42}|  {1, Alice, 28}|\n",
      "|    {2, Bob, 27}|  {1, Alice, 28}|    {2, Bob, 27}|\n",
      "|{3, Charlie, 65}|    {2, Bob, 27}|  {4, David, 42}|\n",
      "|{3, Charlie, 65}|    {2, Bob, 27}|  {1, Alice, 28}|\n",
      "|  {4, David, 42}|  {1, Alice, 28}|    {2, Bob, 27}|\n",
      "|     {5, Ed, 55}|{3, Charlie, 65}|   {6, Fran, 50}|\n",
      "|     {5, Ed, 55}|{3, Charlie, 65}|    {2, Bob, 27}|\n",
      "|     {5, Ed, 55}|    {2, Bob, 27}|  {4, David, 42}|\n",
      "|     {5, Ed, 55}|    {2, Bob, 27}|  {1, Alice, 28}|\n",
      "|   {7, Qing, 27}|{9, Olafson, 17}|{10, Birgit, 33}|\n",
      "|   {7, Qing, 27}| {8, Sarika, 78}|{10, Birgit, 33}|\n",
      "+----------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[]->(b);(b)-[]->(c)\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|    src|   dst|\n",
      "+-------+------+\n",
      "|  Alice| David|\n",
      "|    Bob| Alice|\n",
      "|Charlie| David|\n",
      "|Charlie| Alice|\n",
      "|  David|   Bob|\n",
      "|     Ed|  Fran|\n",
      "|     Ed|   Bob|\n",
      "|     Ed| David|\n",
      "|     Ed| Alice|\n",
      "|   Qing|Birgit|\n",
      "|   Qing|Birgit|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[]->(b);(b)-[]->(c)\").filter(\"a.id != c.id\").select(\"a.name\",\"c.name\").toDF(\"src\",\"dst\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|    src|   dst|\n",
      "+-------+------+\n",
      "|  Alice| David|\n",
      "|    Bob| Alice|\n",
      "|Charlie| David|\n",
      "|Charlie| Alice|\n",
      "|  David|   Bob|\n",
      "|     Ed|  Fran|\n",
      "|     Ed|   Bob|\n",
      "|     Ed| David|\n",
      "|     Ed| Alice|\n",
      "|   Qing|Birgit|\n",
      "|   Qing|Birgit|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[]->(b);(b)-[]->(c)\").filter(\"a.id != c.id\").select($\"a.name\" as \"src\",$\"c.name\" as \"dst\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Making a graph undirected</span>\n",
    "<li>GraphFrames only allows directed graphs</li>\n",
    "<li>But, by keeping only one directed edge between node pairs, we can simulate an undirected graph</li>\n",
    "<li>The code below keeps only one edge between vertices</li>\n",
    "<li>The resulting graph is only sort-of undirected (GraphFrames will assume it is directed)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u_edge_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [src: int, dst: int]\n",
       "u_vertices_df: org.apache.spark.sql.DataFrame = [id: int, name: string ... 1 more field]\n",
       "u_g: org.graphframes.GraphFrame = GraphFrame(v:[id: int, name: string ... 1 more field], e:[src: int, dst: int])\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val u_edge_df = g.find(\"(a)-[]->(b)\") //Get all nodes in a df\n",
    "    .select($\"a.id\".as(\"src\"),$\"b.id\".as(\"dst\")) //use select to rename them src and dst\n",
    "    //create a swap column\n",
    "    //if src id < dst id, then store dst in swap (sort of like temp when swapping values)\n",
    "    .withColumn(\"swap\",when(col(\"src\")<col(\"dst\"),col(\"dst\"))) \n",
    "    //copy src to dst wherever swap is not null\n",
    "    //this will overwrite dst but note that it is saved in swap\n",
    "    .withColumn(\"dst\",\n",
    "                when(col(\"swap\").isNotNull,col(\"src\"))\n",
    "                .otherwise(col(\"dst\")))\n",
    "    //now copy swap to src when swap is not null\n",
    "    //the saved value of dst will be copied to src\n",
    "    .withColumn(\"src\",\n",
    "                when(col(\"swap\").isNotNull,col(\"swap\"))\n",
    "               .otherwise(col(\"src\")))\n",
    "    .drop(col(\"swap\"))\n",
    "    .distinct\n",
    "val u_vertices_df = g.vertices\n",
    "val u_g = GraphFrame(u_vertices_df,u_edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|src|dst|swap|\n",
      "+---+---+----+\n",
      "|  2|  1|   1|\n",
      "|  1|  2|null|\n",
      "|  2|  4|null|\n",
      "|  3|  2|   2|\n",
      "|  3|  6|null|\n",
      "|  4|  1|   1|\n",
      "|  5|  3|   3|\n",
      "|  5|  2|   2|\n",
      "|  5|  6|null|\n",
      "|  7|  9|null|\n",
      "|  7|  8|null|\n",
      "|  9| 10|null|\n",
      "|  8| 10|null|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[]->(b)\")\n",
    ".select($\"a.id\".as(\"src\"),$\"b.id\".as(\"dst\"))\n",
    ".withColumn(\"swap\",when(col(\"src\")>col(\"dst\"),col(\"dst\"))) \n",
    ".withColumn(\"dst\",\n",
    "                when(col(\"swap\").isNotNull,col(\"src\"))  \n",
    "                .otherwise(col(\"dst\")))\n",
    ".withColumn(\"src\",\n",
    "            when(col(\"swap\").isNotNull,col(\"swap\"))\n",
    "           .otherwise(col(\"src\")))\n",
    ".drop(col(\"swap\"))\n",
    ".distinct\n",
    ".show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x=7\n",
    "\n",
    "y=6\n",
    "\n",
    "temp = x\n",
    "\n",
    "x = y\n",
    "\n",
    "y = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  2|  1|\n",
      "|  4|  2|\n",
      "|  3|  2|\n",
      "|  6|  3|\n",
      "|  4|  1|\n",
      "|  5|  2|\n",
      "|  5|  3|\n",
      "|  6|  5|\n",
      "|  9|  7|\n",
      "|  8|  7|\n",
      "| 10|  9|\n",
      "| 10|  8|\n",
      "+---+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "make_undirected_graph: (g: org.graphframes.GraphFrame)org.graphframes.GraphFrame\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Package this into a function\n",
    "def make_undirected_graph(g: GraphFrame) = {\n",
    "    val u_edge_df = g.find(\"(a)-[]->(b)\")\n",
    "        .select($\"a.id\".as(\"src\"),$\"b.id\".as(\"dst\"))\n",
    "        .withColumn(\"swap\",when(col(\"src\")<col(\"dst\"),col(\"dst\")))\n",
    "        .withColumn(\"dst\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"src\"))\n",
    "                    .otherwise(col(\"dst\")))\n",
    "        .withColumn(\"src\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"swap\"))\n",
    "                   .otherwise(col(\"src\")))\n",
    "        .drop(col(\"swap\"))\n",
    "        .distinct\n",
    "    val u_vertices_df = g.vertices\n",
    "    val u_g = GraphFrame(u_vertices_df,u_edge_df)    \n",
    "    u_g\n",
    "}\n",
    "\n",
    "make_undirected_graph(g).edges.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">State carrying Motifs </span>\n",
    "<li>Sometimes, we need to pass state information from one edge to the next</li>\n",
    "<li>For example, if we need to find all paths of length n where the total likes is greater than k</li>\n",
    "<li>We will need to sum likes across n edges for all n-edge paths in the graph</li>\n",
    "<li>Consider the example where n=3 and k=8</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">paths of length 3</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------------+----------+--------------+----------+--------------+\n",
      "|               a|        ab|               b|        bc|             c|        cd|             d|\n",
      "+----------------+----------+----------------+----------+--------------+----------+--------------+\n",
      "|  {1, Alice, 28}|{1, 2, 13}|    {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|\n",
      "|  {1, Alice, 28}|{1, 2, 13}|    {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "|    {2, Bob, 27}| {2, 4, 2}|  {4, David, 42}| {4, 1, 1}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "|    {2, Bob, 27}| {2, 1, 7}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}|\n",
      "|    {2, Bob, 27}| {2, 1, 7}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|\n",
      "|{3, Charlie, 65}| {3, 2, 4}|    {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|\n",
      "|{3, Charlie, 65}| {3, 2, 4}|    {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "|  {4, David, 42}| {4, 1, 1}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}|\n",
      "|  {4, David, 42}| {4, 1, 1}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}| {5, 3, 8}|{3, Charlie, 65}| {3, 2, 4}|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}|\n",
      "|     {5, Ed, 55}| {5, 3, 8}|{3, Charlie, 65}| {3, 2, 4}|  {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}| {5, 2, 2}|    {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}| {5, 2, 2}|    {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "+----------------+----------+----------------+----------+--------------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">paths of length 3 with cycles removed</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|               a|       ab|               b|       bc|             c|       cd|             d|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|{3, Charlie, 65}|{3, 2, 4}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 2, 2}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "    .filter(\"a.id != b.id\")\n",
    "    .filter(\"a.id != c.id\")\n",
    "    .filter(\"a.id != d.id\")\n",
    "    .filter(\"b.id != c.id\")\n",
    "    .filter(\"b.id != d.id\")\n",
    "    .filter(\"c.id != d.id\")\n",
    "    .show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Define a adds the number of likes to a running total on a path</span>\n",
    "<li>Given a column of likes and a column of totals we just add them up!</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sumLikes: (total: org.apache.spark.sql.Column, likes: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sumLikes(total: Column, likes: Column): Column = {\n",
    "  total+likes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">A function that adds up values across the path</span>\n",
    "<li>Use foldLeft to sum the likes in a path</li>\n",
    "<li><span style=\"color:blue\">lit</span> creates a column of whatever value is specified (lit stands for literal)</li>\n",
    "<li>lit(0) is the initial value column</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|one|\n",
      "+---+---+\n",
      "|  1|  0|\n",
      "|  2|  0|\n",
      "|  3|  0|\n",
      "|  4|  0|\n",
      "|  5|  0|\n",
      "|  6|  0|\n",
      "|  7|  0|\n",
      "|  8|  0|\n",
      "|  9|  0|\n",
      "| 10|  0|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertex_df.select($\"id\",lit(0).as(\"one\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition: org.apache.spark.sql.Column = (((0 + ab[attr]) + bc[attr]) + cd[attr])\n"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val condition = Seq(\"ab\", \"bc\", \"cd\")\n",
    "    .foldLeft(lit(0))((total, e) => sumLikes(total, col(e)(\"attr\")))\n",
    "//lit(0)->initialier; total->accu; e->new value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Apply the condition using where</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|               a|       ab|               b|       bc|             c|       cd|             d|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|{3, Charlie, 65}|{3, 2, 4}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 2, 2}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "    .filter(\"a.id != b.id\")\n",
    "    .filter(\"a.id != c.id\")\n",
    "    .filter(\"a.id != d.id\")\n",
    "    .filter(\"b.id != c.id\")\n",
    "    .filter(\"b.id != d.id\")\n",
    "    .filter(\"c.id != d.id\")\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "|          a|       ab|               b|       bc|           c|       cd|             d|\n",
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "|{5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|{2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|{5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|{2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "    .filter(\"a.id != b.id\")\n",
    "    .filter(\"a.id != c.id\")\n",
    "    .filter(\"a.id != d.id\")\n",
    "    .filter(\"b.id != c.id\")\n",
    "    .filter(\"b.id != d.id\")\n",
    "    .filter(\"c.id != d.id\")\n",
    "    .where(condition>8)\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name| name|\n",
      "+----+-----+\n",
      "|  Ed|David|\n",
      "|  Ed|Alice|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "    .filter(\"a.id != b.id\")\n",
    "    .filter(\"a.id != c.id\")\n",
    "    .filter(\"a.id != d.id\")\n",
    "    .filter(\"b.id != c.id\")\n",
    "    .filter(\"b.id != d.id\")\n",
    "    .filter(\"c.id != d.id\")\n",
    "    .where(condition>8)\n",
    "    .select(\"a.name\",\"d.name\")\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name| name|\n",
      "+----+-----+\n",
      "|  Ed|David|\n",
      "|  Ed|Alice|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "//     .filter(\"a.id != b.id\")\n",
    "//     .filter(\"a.id != c.id\")\n",
    "//     .filter(\"a.id != d.id\")\n",
    "//     .filter(\"b.id != c.id\")\n",
    "//     .filter(\"b.id != d.id\")\n",
    "//     .filter(\"c.id != d.id\")\n",
    "//     .select(($\"ab.attr\"+$\"bc.attr\"+$\"cd.attr\").as(\"s\"),$\"a.name\",$\"d.name\")\n",
    "//     .filter($\"s\">8)\n",
    "//     .drop($\"s\")\n",
    "//     .show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Try this</span>\n",
    "<li>Find pairs of friends with path length = 3 and at least 2 edges have likes > 2</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "four_friend_groups_no_dups: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [a: struct<id: int, name: string ... 1 more field>, ab: struct<src: int, dst: int ... 1 more field> ... 5 more fields]\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val four_friend_groups_no_dups = g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "                                    .filter(\"a.id != b.id\")\n",
    "                                    .filter(\"a.id != c.id\")\n",
    "                                    .filter(\"a.id != d.id\")\n",
    "                                    .filter(\"b.id != c.id\")\n",
    "                                    .filter(\"b.id != d.id\")\n",
    "                                    .filter(\"c.id != d.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|               a|       ab|               b|       bc|             c|       cd|             d|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|{3, Charlie, 65}|{3, 2, 4}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 2, 2}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "four_friend_groups_no_dups.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Write a function that adds 1 to a count if likes > 2</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sumLikes: (cnt: org.apache.spark.sql.Column, likes: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sumLikes(cnt: Column, likes: Column): Column = {\n",
    "  when(likes > 2, cnt + 1).otherwise(cnt)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Write the condition</span>\n",
    "<li>Use foldLeft accumulating values using sumLikes</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition: org.apache.spark.sql.Column = CASE WHEN (cd[attr] > 2) THEN (CASE WHEN (bc[attr] > 2) THEN (CASE WHEN (ab[attr] > 2) THEN (0 + 1) ELSE 0 END + 1) ELSE CASE WHEN (ab[attr] > 2) THEN (0 + 1) ELSE 0 END END + 1) ELSE CASE WHEN (bc[attr] > 2) THEN (CASE WHEN (ab[attr] > 2) THEN (0 + 1) ELSE 0 END + 1) ELSE CASE WHEN (ab[attr] > 2) THEN (0 + 1) ELSE 0 END END END\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val condition = Seq(\"ab\", \"bc\", \"cd\").\n",
    "  foldLeft(lit(0))((cnt, e) => sumLikes(cnt, col(e)(\"attr\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Apply the condition</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "|          a|       ab|               b|       bc|           c|       cd|             d|\n",
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "|{5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|{2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|{5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|{2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "four_friend_groups_no_dups.where(condition>=2).show //at least two edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name| name|\n",
      "+----+-----+\n",
      "|  Ed|David|\n",
      "|  Ed|Alice|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "four_friend_groups_no_dups.where(condition>=2).select(\"a.name\",\"d.name\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name| name|\n",
      "+----+-----+\n",
      "|  Ed|David|\n",
      "|  Ed|Alice|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "    .filter(\"a.id != b.id\")\n",
    "    .filter(\"a.id != c.id\")\n",
    "    .filter(\"a.id != d.id\")\n",
    "    .filter(\"b.id != c.id\")\n",
    "    .filter(\"b.id != d.id\")\n",
    "    .filter(\"c.id != d.id\")\n",
    "        .where(condition>=2).select(\"a.name\",\"d.name\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Creating a generalized motif finder</span>\n",
    "<li>Writing expressions of the sort \"(a)-[ab]->(b); (b)-[bc]->(c); (c)-[cd]->(d)\" is not practical in large graphs</li>\n",
    "<li>We'll write a motif finder function for <i>to find all paths of length n where the total likes is greater than k</i></li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Write a function that generates n paths</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res67: String = n1;n2;n3\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array(\"n1\",\"n2\",\"n3\").mkString(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res68: String = (n1)-[e1]->(n2);(n2)-[e2]->(n3);(n3)-[e3]->(n4)\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 to 3).map(i => s\"(n$i)-[e$i]->(n${i + 1})\").mkString(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------------+----------+--------------+----------+--------------+\n",
      "|              n1|        e1|              n2|        e2|            n3|        e3|            n4|\n",
      "+----------------+----------+----------------+----------+--------------+----------+--------------+\n",
      "|  {1, Alice, 28}|{1, 2, 13}|    {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|\n",
      "|  {1, Alice, 28}|{1, 2, 13}|    {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "|    {2, Bob, 27}| {2, 4, 2}|  {4, David, 42}| {4, 1, 1}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "|    {2, Bob, 27}| {2, 1, 7}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}|\n",
      "|    {2, Bob, 27}| {2, 1, 7}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|\n",
      "|{3, Charlie, 65}| {3, 2, 4}|    {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|\n",
      "|{3, Charlie, 65}| {3, 2, 4}|    {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "|  {4, David, 42}| {4, 1, 1}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}|\n",
      "|  {4, David, 42}| {4, 1, 1}|  {1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}| {5, 3, 8}|{3, Charlie, 65}| {3, 2, 4}|  {2, Bob, 27}| {2, 4, 2}|{4, David, 42}|\n",
      "|     {5, Ed, 55}| {5, 3, 8}|{3, Charlie, 65}| {3, 2, 4}|  {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}| {5, 2, 2}|    {2, Bob, 27}| {2, 4, 2}|{4, David, 42}| {4, 1, 1}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}| {5, 2, 2}|    {2, Bob, 27}| {2, 1, 7}|{1, Alice, 28}|{1, 2, 13}|  {2, Bob, 27}|\n",
      "+----------------+----------+----------------+----------+--------------+----------+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "generateAllPaths: (g_f: org.graphframes.GraphFrame, n: Int)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generateAllPaths(g_f: GraphFrame,n: Int) = {\n",
    "    val path = (1 to n).map(i => s\"(n$i)-[e$i]->(n${i + 1})\").mkString(\";\") \n",
    "    val candidates = g_f.find(path) //will all paths that go from n1 to n2 to n3\n",
    "    candidates\n",
    "}\n",
    "\n",
    "generateAllPaths(g,3).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Write a function that removes cycles from a df of n paths</span>\n",
    "<li>Our result contains cycles but we don't want any!</li>\n",
    "<li>Combinations is s scala function that returns an iterator over all combinations of length n given a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res36: Int = 3\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 to 3).map(i => s\"n$i\").combinations(2).length //(n1,n2), (n1,n3), (n2,n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: String = n1\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 to 3).map(i => s\"n$i\").combinations(2).toSeq(0).toSeq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xs: List[Int] = List(5, 2, 3, 4)\n",
       "res78: scala.collection.immutable.IndexedSeq[String] = Vector(List(5, 2) List(5, 3) List(5, 4) List(2, 3) List(2, 4) List(3, 4), List(5, 2) List(5, 3) List(5, 4) List(2, 3) List(2, 4) List(3, 4), List(5, 2) List(5, 3) List(5, 4) List(2, 3) List(2, 4) List(3, 4), List(5, 2) List(5, 3) List(5, 4) List(2, 3) List(2, 4) List(3, 4))\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs = List(5,2,3,4)\n",
    "(1 to xs.length).map (x => xs.combinations(2)).map ( x => x.mkString(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xs: List[Int] = List(5, 2, 3, 4)\n",
       "res90: scala.collection.immutable.IndexedSeq[Iterator[List[Int]]] = Vector(<iterator>, <iterator>, <iterator>, <iterator>)\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xs = List(5,2,3,4)\n",
    "(1 to xs.length).map (x => xs.combinations(2)).map ( x => x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res31: scala.collection.immutable.IndexedSeq[List[Int]] = Vector(List(5, 2), List(5, 2), List(5, 2), List(5, 2))\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 to xs.length).map (x => xs.combinations(2)).map ( x => x.toSeq(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: scala.collection.immutable.IndexedSeq[String] = Vector(List(5, 2), List(5, 2), List(5, 2), List(5, 2))\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 to xs.length).map (x => xs.combinations(2)).map ( x => x.toSeq(0)).map(x=>x.toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res104: Seq[scala.collection.immutable.IndexedSeq[String]] = Stream(Vector(n1, n2), ?)\n"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 to 3).map(i => s\"n$i\").combinations(2).toSeq\n",
    "// .toString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|              n1|       e1|              n2|       e2|            n3|       e3|            n4|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|{3, Charlie, 65}|{3, 2, 4}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 2, 2}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "removeCycles: (df: org.apache.spark.sql.DataFrame, n: Int)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeCycles(df: DataFrame,n: Int) = {\n",
    "    val combs = (1 to n+1).map(i => s\"n$i\").combinations(2) //n+1 nodes for n paths\n",
    "    combs.foldLeft(df)((r,c) => r.filter(c.toSeq(0).toString+\"!=\"+c.toSeq(1).toString) ) //pass dataframe to filter everytime\n",
    "}\n",
    "\n",
    "removeCycles(generateAllPaths(g,3),3).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Package the functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "|         n1|       e1|              n2|       e2|          n3|       e3|            n4|\n",
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "|{5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|{2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|{5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|{2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "+-----------+---------+----------------+---------+------------+---------+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "motifFinder: (g: org.graphframes.GraphFrame, n: Int, k: Int)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def motifFinder(g:GraphFrame,n:Int,k:Int) = {\n",
    "    def generateAllPaths(g_f: GraphFrame,n: Int) = {\n",
    "        val path = (1 to n).map(i => s\"(n$i)-[e$i]->(n${i + 1})\").mkString(\";\")\n",
    "        val candidates = g_f.find(path)\n",
    "        candidates\n",
    "    }\n",
    "    def removeCycles(df: DataFrame,n: Int) = {\n",
    "        val combs = (1 to n+1).map(i => s\"n$i\").combinations(2) //n+1 nodes for n paths\n",
    "        combs.foldLeft(df)((r,c) => r.filter(c.toSeq(0).toString+\"!=\"+c.toSeq(1).toString) )\n",
    "    }\n",
    "    def sumLikes(total: Column, likes: Column): Column = {\n",
    "        total+likes\n",
    "    }\n",
    "    val condition = (1 to n).map(i=>\"e\"+i.toString).toSeq\n",
    "        .foldLeft(lit(0))((total, e) => sumLikes(total, col(e)(\"attr\")))\n",
    "    \n",
    "    removeCycles(generateAllPaths(g,n),n).where(condition>=k)\n",
    "}\n",
    "\n",
    "motifFinder(g,3,8).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Subgraphs</span>\n",
    "<li><span style=\"color:red\">Using motifs</span>: Motif finder in graphframes returns a dataframe of vertices and edges. We need to construct a graph from this manually</li>\n",
    "<li><span style=\"color:red\">filterVertices and filterEdges</span> automatically create subgraphs</li>\n",
    "<li>The resulting graph contains the union of the nodes from the two filters</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_g: org.graphframes.GraphFrame = GraphFrame(v:[id: int, name: string ... 1 more field], e:[src: int, dst: int ... 1 more field])\n"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sub_g = g.filterVertices(\"age > 30\").filterEdges(\"attr>2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the vertices is deleted, the incoming and outgoint edges will delete too. \n",
    "\n",
    "it could be disconeected edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  3|Charlie| 65|\n",
      "|  4|  David| 42|\n",
      "|  5|     Ed| 55|\n",
      "|  6|   Fran| 50|\n",
      "|  8| Sarika| 78|\n",
      "| 10| Birgit| 33|\n",
      "+---+-------+---+\n",
      "\n",
      "+---+---+----+\n",
      "|src|dst|attr|\n",
      "+---+---+----+\n",
      "|  3|  6|   3|\n",
      "|  5|  3|   8|\n",
      "|  5|  6|   3|\n",
      "|  8| 10|   8|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_g.vertices.show\n",
    "sub_g.edges.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Using motifs</span>\n",
    "<li>Motifs return dataframes</li>\n",
    "<li>Extract vertices into a dataframe, edges into a dataframe, and use that to build a new (subgraph) graph</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|               a|       ab|               b|       bc|             c|       cd|             d|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "|{3, Charlie, 65}|{3, 2, 4}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|\n",
      "|     {5, Ed, 55}|{5, 3, 8}|{3, Charlie, 65}|{3, 2, 4}|  {2, Bob, 27}|{2, 1, 7}|{1, Alice, 28}|\n",
      "|     {5, Ed, 55}|{5, 2, 2}|    {2, Bob, 27}|{2, 4, 2}|{4, David, 42}|{4, 1, 1}|{1, Alice, 28}|\n",
      "+----------------+---------+----------------+---------+--------------+---------+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [a: struct<id: int, name: string ... 1 more field>, ab: struct<src: int, dst: int ... 1 more field> ... 5 more fields]\n"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Extract a subgraph using motifs \n",
    "val df = g.find(\"(a)-[ab]->(b);(b)-[bc]->(c);(c)-[cd]->(d)\")\n",
    "    .filter(\"a.id != b.id\")\n",
    "    .filter(\"a.id != c.id\")\n",
    "    .filter(\"a.id != d.id\")\n",
    "    .filter(\"b.id != c.id\")\n",
    "    .filter(\"b.id != d.id\")\n",
    "    .filter(\"c.id != d.id\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  3|Charlie| 65|\n",
      "|  5|     Ed| 55|\n",
      "|  5|     Ed| 55|\n",
      "|  5|     Ed| 55|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"a.*\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  3|Charlie| 65|\n",
      "|  5|     Ed| 55|\n",
      "|  2|    Bob| 27|\n",
      "|  4|  David| 42|\n",
      "|  1|  Alice| 28|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vertices: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, name: string ... 1 more field]\n"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//collect vertices from the subgraph\n",
    "val vertices = df.select(\"a.*\").union(df.select(\"b.*\")).union(df.select(\"c.*\")).union(df.select(\"d.*\")).distinct\n",
    "vertices.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edges: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [src: int, dst: int ... 1 more field]\n"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//collect edges from the subgraph\n",
    "val edges = df.select(\"ab.*\").union(df.select(\"bc.*\")).union(df.select(\"cd.*\")).distinct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_g1: org.graphframes.GraphFrame = GraphFrame(v:[id: int, name: string ... 1 more field], e:[src: int, dst: int ... 1 more field])\n"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//create a new subgraph with these vertices and edges\n",
    "val sub_g1 = GraphFrame(vertices,edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  3|Charlie| 65|\n",
      "|  5|     Ed| 55|\n",
      "|  2|    Bob| 27|\n",
      "|  4|  David| 42|\n",
      "|  1|  Alice| 28|\n",
      "+---+-------+---+\n",
      "\n",
      "+---+---+----+\n",
      "|src|dst|attr|\n",
      "+---+---+----+\n",
      "|  3|  2|   4|\n",
      "|  5|  3|   8|\n",
      "|  5|  2|   2|\n",
      "|  2|  4|   2|\n",
      "|  4|  1|   1|\n",
      "|  2|  1|   7|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sub_g1.vertices.show\n",
    "sub_g1.edges.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">Constructing the subgraph from a simple motif</span>\n",
    "<li>construct a subgraph that contains all edges with likes > 1 and where the source age is less than the destination age</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paths: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [a: struct<id: int, name: string ... 1 more field>, e: struct<src: int, dst: int ... 1 more field> ... 1 more field]\n",
       "vertices: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, name: string ... 1 more field]\n",
       "edges: org.apache.spark.sql.DataFrame = [src: int, dst: int ... 1 more field]\n",
       "g2: org.graphframes.GraphFrame = GraphFrame(v:[id: int, name: string ... 1 more field], e:[src: int, dst: int ... 1 more field])\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val paths = { g.find(\"(a)-[e]->(b)\")\n",
    "  .filter(\"e.attr > 5\")\n",
    "  .filter(\"a.age < b.age\") }\n",
    "\n",
    "val vertices = paths.select(\"a.*\").union(paths.select(\"b.*\"))\n",
    "val edges = paths.select(\"e.*\")\n",
    "\n",
    "// Construct the subgraph\n",
    "val g2 = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------------+\n",
      "|               a|         e|               b|\n",
      "+----------------+----------+----------------+\n",
      "|    {2, Bob, 27}| {2, 1, 7}|  {1, Alice, 28}|\n",
      "|     {5, Ed, 55}| {5, 3, 8}|{3, Charlie, 65}|\n",
      "|   {7, Qing, 27}|{7, 8, 14}| {8, Sarika, 78}|\n",
      "|{9, Olafson, 17}|{9, 10, 6}|{10, Birgit, 33}|\n",
      "+----------------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paths.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
