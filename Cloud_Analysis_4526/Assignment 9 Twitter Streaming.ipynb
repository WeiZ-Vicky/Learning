{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003f6db1",
   "metadata": {},
   "source": [
    "<h1>Twitter Streaming Assignment</h1>\n",
    "In this assignment, you need to calculate the average sentiment of selected tweets and draw a dynamic graph that shows how this average sentiment is changing over time. Roughly, you need to:\n",
    "\n",
    "<li>create a twitter stream listener</li>\n",
    "<li>collect tweets in batches</li>\n",
    "<li>get the sentiment associated with each tweet</li>\n",
    "<li>create windows on the stream</li>\n",
    "<li>calculate the average sentiment within each window</li>\n",
    "<li>create a dynamic graph that updates every x seconds with the window time on the x axis and the average sentiment in the window on the y-axis</li>\n",
    "\n",
    "<h2>The graph</h2>\n",
    "<li>Note that the graph will pop up in a separate window</li>\n",
    "<li>Which may be behind your browser - so look for it!</li>\n",
    "\n",
    "\n",
    "<h2>Resources required</h2>\n",
    "<li><span style=\"color:blue\">streaming twitter</span>: based on the java twitter library <span style=\"color:blue\">twitter4j</span>, this library provides Spark streaming support for twitter</li>\n",
    "<li><span style=\"color:blue\">JFree Chart</span>: a java library for drawing charts (<a href=\"https://www.jfree.org/jfreechart/javadoc/index.html\">https://www.jfree.org/jfreechart/javadoc/index.html</a></li>\n",
    "<li><b>Note:</b> I've given examples of what you need from these libraries below and all you'll need to bring to the assignment is your knowledge of Scala and Spark</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9791c",
   "metadata": {},
   "source": [
    "<h2>Twitter developer account</h2>\n",
    "<li>Create a twitter developer account by following the instructions at https://developer.twitter.com/en/support/twitter-api/developer-account</li>\n",
    "<li>Note that you will first need to create a twitter user account</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d1c39",
   "metadata": {},
   "source": [
    "<h2>World cup sentiment</h2>\n",
    "<li>We'll analyze the changes in sentiment for the ongoing 2022 Football World Cup in Qatar</li>\n",
    "<li>The basic process:</li>\n",
    "<ul>\n",
    "    <li>Save your twitter keys in the various key variables and convert them to Java properties (see below)</li>\n",
    "    <li>Read in a list of words that will help identify if a tweet is about the world cup (file: fifa2022_words.txt)</li>\n",
    "    <li>Read in a list of (word, sentiment) pairs (file AFINN-111.txt). Sentiment scores for words vary from -3 to +3</li>\n",
    "    <li>Initiate a twitter stream</li>\n",
    "    <li>Filter the stream to include only english tweets</li>\n",
    "    <li>Extract the text from each tweet and see if ANY of the words in the filter list are present in the tweet. If even one of the words is present, keep the tweet. Otherwise discard it</li>\n",
    "    <li>Convert each tweet into an array of words and then each rdd into a single array of words (i.e., use flatMap for converting an rdd into words)\n",
    "    <li>Join each RDD with the sentiment scores. You'll need to count the total number of words, and for the words that have a sentiment, multiply the count by the sentiment. Then, add up all the resulting values and divide by the total number of words</li>\n",
    "    <li>Accumulate each sentiment in a mutable Array Buffer</li>\n",
    "    <li>Follow the steps to draw and update a chart as the sentiment changes</li>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c8ecc7",
   "metadata": {},
   "source": [
    "<h3>Notes on the chart</h3>\n",
    "<li>We're using an XYLineChart from JFreeChart</li>\n",
    "<li>Both the x and the y axes are numbers</li>\n",
    "<li>In our case, the x-axis is Int (unix time values) and the y-axis is Double (sentiment averages)</li>\n",
    "<li>We'll construct a window on our stream and calculate the  sentiment in that window. The time stamp for the window is the x-axis value and the sentiment is the y-axis value</li>\n",
    "<li>x and y values are stored in an XYSeries object (https://www.jfree.org/jfreechart/api/javadoc/org/jfree/data/xy/XYSeries.html) and, as each new value arrives, the addOrUpdate function updates the graph with the new value</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c52de7",
   "metadata": {},
   "source": [
    "<h2>Installing packages</h2>\n",
    "<li>The two packages you need to install are spark-streaming-twitter_2.12:2.4.0 and org.jfree:jfreechart:1.5.3</li>\n",
    "<li>Run the next cell before you run any code to initialize Spark</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f9327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.num_executors = 4\n",
    "launcher.executor_cores = 2\n",
    "launcher.driver_memory = '10g'\n",
    "launcher.packages= [\"org.apache.bahir:spark-streaming-twitter_2.12:2.4.0\",\n",
    "                   \"org.jfree:jfreechart:1.5.3\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b121ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.149:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1670384061109)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebe9bd",
   "metadata": {},
   "source": [
    "<h2>Outer join of two rdds</h2>\n",
    "<li>You're going to need this. The next cell gives an example</li>\n",
    "<li>For joins to work on rdds, both rdds must be Paired RDDs</li>\n",
    "<li>Note that an RDD of (String, (Option[Int],Option[Int])) is returned. Use match and case to remove the option for each possible combination</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec9856c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.rdd.PairRDDFunctions._\n",
       "rdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[0] at parallelize at <console>:25\n",
       "rdd1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[1] at parallelize at <console>:26\n",
       "outer_joined_rdd: org.apache.spark.rdd.RDD[(String, (Option[Int], Option[Int]))] = MapPartitionsRDD[4] at fullOuterJoin at <console>:27\n",
       "res1: Array[(String, (Option[Int], Option[Int]))] = Array((is,(Some(-1),Some(1))), (world,(None,Some(1))), (not,(Some(2),None)), (good,(Some(2),Some(1))), (this,(None,Some(1))))\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.rdd.PairRDDFunctions._\n",
    "val rdd2 = sc.parallelize(Array((\"this\",1),(\"is\",1),(\"world\",1),(\"good\",1)))\n",
    "val rdd1 = sc.parallelize(Array((\"good\",2),(\"is\",-1),(\"not\",2)))\n",
    "val outer_joined_rdd = rdd1.fullOuterJoin(rdd2)\n",
    "outer_joined_rdd.collect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3b862",
   "metadata": {},
   "source": [
    "<h2>Checking to see if ANY of the strings in an array is in a string</h2>\n",
    "<li>The function <b>contains</b> returns true if a string is contained in another string</li>\n",
    "<li>The function <b>exists</b> returns true if any element in a sequence satisfies a condition</li>\n",
    "<li>Use a combination of exists and contains to see if ANY of the strings in an array a is in a string s</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5bbe0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contains_example: Boolean = true\n",
       "exists_example_true: Boolean = true\n",
       "exists_example_false: Boolean = false\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val contains_example = \"The world cup is in Qatar this year\".contains(\"Qatar\")\n",
    "val exists_example_true = Array(1,3,5,7,8,13).exists(v => v%2==0)\n",
    "val exists_example_false = Array(1,3,5,7,9,13).exists(v => v%2==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29eb9f",
   "metadata": {},
   "source": [
    "<h2>Mutable Array Buffer</h2>\n",
    "<li>Scala Array is mutable in content but not mutable in size</li>\n",
    "<li>An ArrayBuffer object is mutable in content as well as size</li>\n",
    "<li>The += operator adds a new element at the back of the array</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0bc1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayBuffer(5.8, -2.4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import scala.collection.mutable.ArrayBuffer\n",
       "mutable_array_example: scala.collection.mutable.ArrayBuffer[Double] = ArrayBuffer(5.8, -2.4)\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ArrayBuffer\n",
    "var mutable_array_example = ArrayBuffer[Double]()\n",
    "mutable_array_example += 5.8\n",
    "mutable_array_example += -2.4\n",
    "println(mutable_array_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18c924",
   "metadata": {},
   "source": [
    "<h1>Do the assignment</h1>\n",
    "<li>Follow the steps below and fill in the pieces of code wherever necessary</li>\n",
    "<li>If you run into serializability errors, put all the code in a single cell and rerun it</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c693f",
   "metadata": {},
   "source": [
    "<h2>Set twitter keys</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc5622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// val CONSUMER_KEY = \"MgWa1tEhKu863diqEdpJhSwhk\"\n",
    "// val CONSUMER_SECRET = \"NY1pq2DJ3QKKEGKiRvrNZLAvxV095yh6eaDnQbEazp3TS369QP\"\n",
    "// val ACCESS_TOKEN = \"1597350057111584768-AjcWhOV1TgkmrX6wGKRTwV1kFMmasy\"\n",
    "// val ACCESS_TOKEN_SECRET = \"EWfirqvdRMObkAJQXjsLIkm92cHttRMAcHi4Nq0MTA9cG\"\n",
    "\n",
    "// //Twitter API keys attached to twitter4j\n",
    "// System.setProperty(\"twitter4j.oauth.consumerKey\",CONSUMER_KEY)\n",
    "// System.setProperty(\"twitter4j.oauth.consumerSecret\",CONSUMER_SECRET)\n",
    "// System.setProperty(\"twitter4j.oauth.accessToken\",ACCESS_TOKEN)\n",
    "// System.setProperty(\"twitter4j.oauth.accessTokenSecret\",ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096aacb",
   "metadata": {},
   "source": [
    "<h2>Data preparation functions and twitter stream setup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7e50a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.streaming.{Seconds, StreamingContext}\n",
       "import org.apache.spark.streaming.twitter._\n",
       "import org.apache.spark.rdd.PairRDDFunctions._\n",
       "import scala.collection.mutable.ArrayBuffer\n",
       "import scala.io.Source\n",
       "import org.jfree.data.xy.{XYSeries, XYSeriesCollection}\n",
       "import org.jfree.chart.{ChartFactory, ChartFrame, JFreeChart}\n",
       "import org.jfree.chart.plot.{PlotOrientation, XYPlot}\n",
       "import org.jfree.chart.util.PaintUtils\n",
       "import java.awt.Paint\n",
       "import java.awt.Color._\n",
       "filters: Array[String] = Array(fifa, qatar, soccer, football, world cup, ronaldo, cristiano, messi, usa, brazil, france, ecuador, senegal, netherlands, iran, england, wales, argentina, saudi arabia, mexico, poland, australia, denmark, tunisia, spain, costa rica, germany, japan, belgium, canada, morocco, croatia, serbia...\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//All the imports you will need\n",
    "\n",
    "import org.apache.spark.streaming.{Seconds, StreamingContext}\n",
    "import org.apache.spark.streaming.twitter._\n",
    "import org.apache.spark.rdd.PairRDDFunctions._\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import scala.io.Source\n",
    "import org.jfree.data.xy.{XYSeries, XYSeriesCollection} \n",
    "import org.jfree.chart.{ChartFactory, ChartFrame, JFreeChart} \n",
    "import org.jfree.chart.plot.{PlotOrientation, XYPlot} \n",
    "import org.jfree.chart.util.PaintUtils\n",
    "import java.awt.Paint\n",
    "import java.awt.Color._\n",
    "\n",
    "//Read the key words that will identify world cup texts\n",
    "//(Adjust the path if your file is in a different folder)\n",
    "//Read these into a Scala Array\n",
    "val filters = Source.fromFile(\"fifa2022_words.txt\").getLines.toArray\n",
    "\n",
    "\n",
    "//Read (word,sentiment pairs into an RDD)\n",
    "val sentimentFilePath = \"AFINN-111.txt\"\n",
    "\n",
    "val wordSentiments = sc.textFile(sentimentFilePath).map { line => \n",
    "    //FILL THIS IN\n",
    "    (line.split(\"\\t\")(0),line.split(\"\\t\")(1).toDouble)\n",
    "}.cache()\n",
    "\n",
    "//Write a function getWords that takes a string and breaks it up into an array of words\n",
    "//Example: \"Jack, the man\\nWoolly the mammoth!\" should generate the array\n",
    "//   Array(Jack, the, man, Woolly, the, mammoth)\n",
    "//or: remove punctuation and replace \\n by a space. \n",
    "//The isLetter function returns true if a character is a letter\n",
    "\n",
    "def getWords(text: String): Array[String] = {\n",
    "    //FILL THIS IN\n",
    "    text.split(\" \").map(a=>a.toArray.filter(b=>b.isLetter)).map(c=>c.mkString)\n",
    "}\n",
    "\n",
    "//Set up the stream and get the text of each tweet\n",
    "val ssc = new StreamingContext(sc,Seconds(10.toLong))\n",
    "ssc.checkpoint(\"checkpoint\")\n",
    "val text = ssc.socketTextStream(\"localhost\", 4444)\n",
    "// val stream = TwitterUtils.createStream(ssc, None, Array[String]())\n",
    "// val tweets = stream.filter(_.getLang == \"en\")\n",
    "// val text = tweets.map(status => status.getText)\n",
    "\n",
    "//filter tweets only keeping world cup related ones\n",
    "//Use transform to work on each rdd (text is a DStream object, not an RDD)\n",
    "//filter using exists and contains\n",
    "//Also, convert the text to lowercase (all the keywords are in lowercase)\n",
    "val filteredText = text.transform(\n",
    "                    rdd => rdd.filter( //rdd\n",
    "                        a => filters.exists( //element\n",
    "                            key => a.toLowerCase().contains(key))))\n",
    "\n",
    "//convert all tweets in filteredText into a single array of words (think flatMap)\n",
    "val words = filteredText.flatMap(getWords(_))\n",
    "\n",
    "//get sentiments\n",
    "//we need to convert each word into a pair (word, 1) to count the number of words\n",
    "//apply transform to join each rdd with the wordSentiment rdd using fullOuterJoin\n",
    "//Use match to convert Option to a new paired rdd (count, 1*sentiment)\n",
    "\n",
    "val sentiment = words.map(word => (word, 1.0))\n",
    "                  .transform{\n",
    "                      rdd => rdd.fullOuterJoin(wordSentiments)\n",
    "                          .flatMap(pair => pair match {\n",
    "                                    case (word,(Some(count),None)) => Some(0.0,0.0)\n",
    "                                    case (word,(None,senti)) => None\n",
    "                                    case (word,(Some(count),Some(senti))) => Some(count,1*senti)\n",
    "                                    }\n",
    "                              )\n",
    "                            }\n",
    "\n",
    "\n",
    "//Define a window of length 120 that slides every 40 seconds\n",
    "val sentiment_window = sentiment.window(Seconds(120),Seconds(40))\n",
    "\n",
    "//Create an empty ArrayBuffer all_sentiments that contains sentiments\n",
    "//And a second array buffer that contains the (timestamp,moving average)\n",
    "//Because we'll modify them, these need to be var, not val\n",
    "\n",
    "val MOVING_AVERAGE_LENGTH = 3\n",
    "\n",
    "var all_sentiments = ArrayBuffer[Double]()\n",
    "var all_averages = ArrayBuffer[(String,Double)]()\n",
    "\n",
    "/*\n",
    "1. apply foreachRDD to each sentiment window\n",
    "\n",
    "2. Update all_sentiments by the sentiment of the rdd (divide total sentiment by the count\n",
    "of all words and multiply by 100.0\n",
    "\n",
    "3. Calculate the total for count and sentiment (sentiment should be (Double,Double) pairs)\n",
    "Example of all_sentiments:\n",
    "res6: scala.collection.mutable.ArrayBuffer[Double] = ArrayBuffer(0.17157852240613647, 0.10092344956350609, \n",
    "0.10092175200161475, 0.07737334320123797, \n",
    "0.19847944560317568, 0.20185029436501262, \n",
    "0.1883936080740118, 0.10765711209796798, \n",
    "0.04709998654286099, 0.026914278024491995)\n",
    "\n",
    "4. Compute the moving average. If the number of elements in all_sentiments is less \n",
    "than MOVING_AVERAGE_LENGTH, then a simple average works. If greater, then compute\n",
    "the average of the last MOVING_AVERAGE_LENGTH elements (the scala function slice may help)\n",
    "\n",
    "5. Uodate all_averages with the timestamp (cleaned) and the moving average. Example:\n",
    "ArrayBuffer((5820000,0.17157852240613647), \n",
    "(5860000,0.13625098598482127), \n",
    "(5900000,0.12447457465708577), \n",
    "(5940000,0.09307284825545294), \n",
    "(5980000,0.12559151360200946), \n",
    "(6020000,0.15923436105647543), \n",
    "(6060000,0.19624111601406669), \n",
    "(6100000,0.16596700484566412), \n",
    "(6140000,0.1143835689049469), \n",
    "(6180000,0.060557125555107))\n",
    "\n",
    "6. You also need to clean the timestamp. Convert it into a string, \n",
    "drop the \"ms\" from the end, and then drop everything other than last 7 digits\n",
    "You might find the function takeRight useful\n",
    "\n",
    "*/\n",
    "sentiment_window.foreachRDD((r,t) => {\n",
    "    val sum = r.map(t => t._2).fold(0.0)((a,b)=>a+b)\n",
    "    val count = r.count()\n",
    "    val clean_timestamp = t.toString.dropRight(3).takeRight(9)\n",
    "    all_sentiments += (sum/count) * 100.0\n",
    "    //during some window, the input can be empty, the sentiment will be NaN. \n",
    "    //NaN will affect all_averages, so I filter NaN first.\n",
    "    all_sentiments = all_sentiments.filter(x=> !x.isNaN)\n",
    "    if (all_sentiments.length >= 1) {\n",
    "        if (all_sentiments.length == 1) all_averages += ((clean_timestamp, all_sentiments(0)))\n",
    "        else if (all_sentiments.length < MOVING_AVERAGE_LENGTH)\n",
    "                all_averages += ((clean_timestamp,all_sentiments.sum/all_sentiments.length))\n",
    "        else {\n",
    "    //val slice = all_sentiments.takeRight(MOVING_AVERAGE_LENGTH)\n",
    "            val slice = all_sentiments.slice(all_sentiments.length-3,all_sentiments.length+1)\n",
    "            all_averages += ((clean_timestamp,slice.sum/MOVING_AVERAGE_LENGTH))\n",
    "        }\n",
    "\n",
    "    //Print new values\n",
    "        println(all_sentiments(all_sentiments.length-1),all_averages(all_averages.length-1))\n",
    "    }\n",
    "})\n",
    "//Configure and show the (initally empty) chart\n",
    "//I've done all the chart work for you\n",
    "\n",
    "\n",
    "//Create a new XYSeries object that holds the data for the graph \n",
    "//And a dataset that contains this XYSeries object\n",
    "//The goal is to update xy whenever there is a new average in all_averages\n",
    "\n",
    "val xy = new XYSeries(\"\") \n",
    "val dataset = new XYSeriesCollection(xy)\n",
    "\n",
    "//Creates the chart object \n",
    "val chart = ChartFactory.createXYLineChart( \n",
    "  \"2022 World Cup Sentiment Chart\",  // chart title \n",
    "  \"Time\",               // x axis label \n",
    "  \"Sentiment\",                   // y axis label \n",
    "  dataset,                   // data \n",
    "  PlotOrientation.VERTICAL, \n",
    "  false,                    // include legend \n",
    "  true,                     // tooltips \n",
    "  false                     // urls \n",
    ")\n",
    "\n",
    "//From the chart, grab the plot so that we can configure formatting info (done for you)\n",
    "\n",
    "val plot = chart.getXYPlot() \n",
    "\n",
    "def configurePlot(plot: XYPlot): Unit = { \n",
    "  plot.setBackgroundPaint(WHITE) \n",
    "  plot.setDomainGridlinePaint(BLACK) \n",
    "  plot.setRangeGridlinePaint(BLACK) \n",
    "  plot.setOutlineVisible(false) \n",
    "} \n",
    "\n",
    "//A function that shows the chart.\n",
    "def show(chart: JFreeChart) { \n",
    "  val frame = new ChartFrame(\"plot\", chart) \n",
    "  frame.pack() \n",
    "  frame.setVisible(true) \n",
    "}\n",
    "\n",
    "//Call the plot configuration function\n",
    "//Call the show chart function (now it will actually pop up)\n",
    "//Note that the chart is in a separate window so you might need to look for it\n",
    "\n",
    "configurePlot(plot) \n",
    "show(chart) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f115dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.8867924528301887,(384350000,-1.8867924528301887))\n",
      "(-1.0752688172043012,(384390000,-1.481030635017245))\n",
      "(-0.9592326139088728,(384430000,-1.3070979613144542))\n",
      "(-0.6430868167202572,(384470000,-0.8925294159444771))\n",
      "(-0.6134969325153374,(384510000,-0.7386054543814892))\n",
      "(0.0,(384550000,-0.4188612497451982))\n",
      "(-2.4390243902439024,(384590000,-1.0175071075864133))\n",
      "(-4.166666666666666,(384630000,-2.2018970189701896))\n",
      "(-4.166666666666666,(384670000,-3.5907859078590785))\n",
      "(0.0,(384710000,-2.7777777777777772))\n",
      "22/12/06 22:45:15 ERROR ReceiverTracker: Deregistered receiver for stream 0: Stopped by driver\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NUM_BATCHES: Int = 10\n",
       "index: Int = 10\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "1. Start the stream\n",
    "2. Inside a while loop, sleep for a bit (Thread.sleep(10000) for 10 seconds)\n",
    "3. then check if there are new elements in all_averages\n",
    "\n",
    "4. To check if there are new elements, initialize a variable index to 0 and,\n",
    "at each interval (after sleep), check if the array length of all_averages is\n",
    "greater than index. If it is, there are length-index new elements\n",
    "\n",
    "5. if there are new elements, add them to xy using addOrUpdate (see documentation linked above)\n",
    " add the elements in all_averages.length - previous_length to xy ()\n",
    "Use addOrUpdate (not add) so that the graph updates\n",
    "\n",
    "6. The while should run as long as the length of all_averages is less than NUM_BATCHES\n",
    "\n",
    "7. Call ssc.stop(false) after the while loop\n",
    "\n",
    "8. Note that once the stream stops, DStream elements are no longer accessible but\n",
    "RDDs are (all_sentiments and all_averages)\n",
    "\n",
    "9. Enjoy! Do note that for this to make sense, we should run this for a long time and \n",
    "take a moving average of a longer period (e.g., several hours). Treat this as a\n",
    "learning exercise, not a diagnostic one\n",
    "\n",
    "*/\n",
    "\n",
    "val NUM_BATCHES = 10 //So that you don't get banned from twitter\n",
    "var index = 0\n",
    "ssc.start\n",
    "while (all_averages.length < NUM_BATCHES ) {\n",
    "    Thread.sleep(10000);\n",
    "    var len = all_averages.length\n",
    "    if (len > index) {\n",
    "        index = len\n",
    "        xy.addOrUpdate(all_averages(all_averages.length-1)._1.toDouble, all_averages(all_averages.length-1)._2)\n",
    "    }\n",
    "    \n",
    "}\n",
    "ssc.stop(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7758d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "// (clean_timestamp, all_sentiments(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f63658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
